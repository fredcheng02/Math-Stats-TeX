\documentclass[10pt]{article}
\usepackage[T1]{fontenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{tikz-cd}
\usepackage{enumitem}
\usepackage{setspace,microtype}
\usepackage{soul,framed}
\usepackage[dvipsnames]{xcolor}
\usepackage[pdfusetitle,bookmarks,bookmarksnumbered,bookmarksopen,bookmarksopenlevel=1,colorlinks,
citecolor=CornflowerBlue,urlcolor=CornflowerBlue,linkcolor=BurntOrange]{hyperref}
\usepackage[capitalize]{cleveref}
\usepackage[all]{hypcap}

\usepackage{titlesec}
\titleformat*{\section}{\Large}
\titleformat*{\subsection}{\large}

\usepackage{titletoc}
\contentsmargin{2.4em}
\titlecontents{section}
[2em] 
{\addvspace{.5\baselineskip}}
{\contentslabel{2em}}
{\hspace*{-2em}}
{\hfill\contentspage}
\titlecontents{subsection}
[4.8em]
{}
{\contentslabel{2.8em}}
{\hspace*{-2.8em}}
{\titlerule*[1pc]{.}\contentspage}

% no parentheses
\newtheoremstyle{plain-star}{\topsep}{\topsep}{}{}{\sffamily}{.}{5pt plus 1pt minus 1pt}{\thmnumber{#2 }\thmname{#1}\thmnote{ #3}}

\newtheoremstyle{definition-star}{\topsep}{\topsep}{}{}{\sffamily}{.}{5pt plus 1pt minus 1pt}{\thmnumber{#2 }\thmname{#1}\thmnote{ (#3)}}

\newtheoremstyle{remark-star}{.5\topsep}{.5\topsep}{}{}{\itshape\sffamily}{.}{5pt plus 1pt minus 1pt}{\thmnumber{#2 }\thmname{#1}\thmnote{ (#3)}}

\renewcommand\thesubsection{\thesection.\Alph{subsection}}
\numberwithin{equation}{section}
\theoremstyle{plain-star}
\newtheorem{thm}[equation]{Theorem}
\newtheorem*{thm*}{Theorem}
\newtheorem{prop}[equation]{Proposition}
% \newtheorem*{prop*}[equation]{Proposition}
\newtheorem{fact}[equation]{Fact}
\newtheorem{lem}[equation]{Lemma}
\newtheorem{cor}[equation]{Corollary}
\theoremstyle{definition-star}
\newtheorem{defn}[equation]{Definition}
\newtheorem{exa}[equation]{Example}
\newtheorem{xca}[equation]{Exercise}
\theoremstyle{remark-star}
\newtheorem{rem}[equation]{Remark}
\newtheorem*{rem*}{Remark}

\newenvironment{sketch}[1][Sketch]{\begin{proof}[#1]\renewcommand*{\qedsymbol}{$\triangle$}}{\end{proof}}

\makeatletter
\newcommand\thmsname{Theorem}
\newcommand\nm@thmtype{theorem}
\theoremstyle{plain-star}
\newtheorem{namedtheorem}[equation]{\thmsname}
\newenvironment{namedthm}[1][Undefined Theorem Name]{
    \ifx{#1}{Undefined Theorem Name}
    \renewcommand\nm@thmtype{theorem}
    \else\renewcommand\thmsname{#1}
    \renewcommand\nm@thmtype{namedtheorem}
    \fi
    \begin{\nm@thmtype}\def\@currentlabelname{#1}}
    {\end{\nm@thmtype}}

\newtheorem*{namedtheorem*}{\thmsname}
\newenvironment{namedthm*}[1][Undefined Theorem Name]{
    \ifx{#1}{Undefined Theorem Name} \renewcommand\nm@thmtype{theorem*}
    \else\renewcommand\thmsname{#1}
    \renewcommand\nm@thmtype{namedtheorem*}
    \fi
    \begin{\nm@thmtype}}
    {\end{\nm@thmtype}}
\makeatother

% \renewcommand{\arraystretch}{1.2}

\setlength{\parskip}{0em} % default parskip
\setlist{listparindent=\parindent,parsep=0pt,left=\parindent} % indentation and separation between list paragraphs
\setenumerate[1]{label=(\alph*)}

\makeatletter
% \onehalfspacing
\usepackage{xpatch}
\xpatchcmd{\env@cases}{1.2}{1.1}{}{}
\xpatchcmd{\proof}{\itshape}{\normalfont\proofnamefont}{}{}
\newcommand{\proofnamefont}{\itshape\sffamily}

\let\@subtitle\@empty % default value
\protected\def\subtitle#1{\gdef\@subtitle{#1}}
\def\@maketitle{%
  \newpage
  \begin{center}%
  \let \footnote \thanks
    {\Large\sffamily \@title \par}% % LARGE
    {\sffamily \@subtitle \par}% % large
    \vskip 0.5em%
    {\lineskip .5em%
      \begin{tabular}[t]{c}%
        \sffamily \@author
      \end{tabular}\par}%
    {\sffamily \@date}%
    \vskip -0.5em%
  \end{center}%
  \par}
\makeatother

\newcommand{\R}{\mathbf{R}}
\newcommand{\C}{\mathbf{C}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\N}{\mathbf{N}}
\newcommand{\Q}{\mathbf{Q}}
\newcommand{\ind}{\mathbf{1}}
\renewcommand{\Pr}{P}
\newcommand{\E}{\mathop{}\!\mathrm{E}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\giv}{\,|\,}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\Mat}{\operatorname{Mat}}
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\cpl}{\mathrm{c}}
\newcommand{\trp}{\mathrm{T}}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\inp}[2]{\langle #1, #2 \rangle}
\newcommand{\nm}[1]{\lVert #1 \rVert}
\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\blank}{\,\cdot\,}
\renewcommand{\phi}{\varphi}
\renewcommand{\implies}{\Rightarrow}
\renewcommand{\impliedby}{\Leftarrow}

\newcommand{\df}[1]{\textit{#1}}

\usepackage[style=alphabetic,doi=false,url=false,isbn=false]{biblatex}
\addbibresource{MP.bib}
\renewbibmacro{in:}{}

% disable automatic page designation
\DeclareFieldFormat{postnote}{#1}


\title{From Measure to Probability}
\subtitle{A survey of measure-theoretic results for mathematical probabilists}
\author{Feng Cheng}
\date{}

\begin{document}
\maketitle

\tableofcontents
\newpage
\part*{\Large Acknowledgement}

This is the most ambitious writing project undertaken by the author so far as a math student, and he hopes he can finish it in two years. The author, as a probability student, did not excel in his real analysis courses (MATH 202AB at UC Berkeley) during his senior year. To compensate, the author aims to write an extensive and detailed note that surveys through all the major measure theory results of interest to a rigorous-minded mathematical probabilist.

Part I of this note will be devoted to measure theory in a general setting, while Part II will discuss results in probability spaces built on top of Part I. The author hopes that his commentary and the overall structure of the survey can help the readers (and himself) truly understand both abstract measure theory and probability theory from a measure-theoretic point of view.

This entire survey will be based on multiple sources, listed in the bibliography page. As the old saying goes, ``if you copy from one book that is plagiarism, but if you copy from ten books that is scholarship.''
\vspace{1\baselineskip}

\noindent Shanghai, August 2024 \hfill F.C.
\newpage

\part{Measure theory}
\section{Measure spaces and construction of measures}
\subsection{Basic setup}
We let $X$ be a nonempty set in Part I.
\begin{defn}
    For $\{A_n\}_{n=1}^\infty\subseteq \wp(X)$, we define \[
        \limsup_{n \to \infty} A_n = \bigcap_{n=0}^\infty \bigcup_{m=n}^\infty A_m \quad \text{and}\quad \liminf_{n \to \infty} A_n = \bigcup_{n = 0}^\infty \bigcap_{m = n}^\infty A_m.
    \]
\end{defn}
Note $\bigcap$ can be seen as ``for all'' and $\bigcup$ can be seen as ``there exists''. Therefore $\limsup_n A_n$ consists of elements that belong to infinitely many $A_n$'s (spread out across $n \in \N$), while $\liminf_n A_n$ consists of elements that belong to all but finitely $A_n$ (the $n$'s at the beginning). Compare this with the $\limsup$ and $\liminf$ of a sequence of numbers; for example, one may try the following exercise.

\begin{xca}
    Show that \begin{align*}
        \limsup_{n \to \infty}  A_n = A & \iff \limsup_{n \to \infty} \ind_{A_n} = \ind_A, \\
        \liminf_{n \to \infty}  A_n = A & \iff \liminf_{n \to \infty} \ind_{A_n} = \ind_A.
    \end{align*}

    Here $\ind_A\colon X \to \{0,1\}$ given by \[
        \ind_A(x)= \begin{cases}
            1 & \text{if } x \in A, \\
            0 & \text{if } x \not\in A.
        \end{cases}
    \]
    is called the \df{indicator function} (\df{characteristic function} for analysts who choose to write $\chi_A$).
\end{xca}

If $\{A_n\}_{n=1}^\infty$ is an increasing sequence of sets, then \[
    \liminf_n A_n = \limsup_n A_n = \bigcup_n A_n;
\] if the sequence is decreasing, then \[
    \liminf_n A_n = \limsup_n A_n = \bigcap_n A_n.
\] Also remember that \[
    \limsup_n A_n^\cpl = \bigl(\liminf_n A_n\bigr)^\cpl \quad \text{and}\quad 
    \liminf_n A_n^\cpl = \bigl(\limsup_n A_n \bigr)^\cpl.
\]

\begin{defn}
    A nonempty collection of subsets of $X$ is an \df{algebra} if \begin{enumerate}
        \item $\emptyset,X \in \A$;
        \item closed under complement;
        \item \label{enu:algebra-finite-union} closed under finite unions and intersections.
    \end{enumerate}
    Furthermore, $\A$ is called a \df{$\sigma$-algebra} if condition~\ref{enu:algebra-finite-union} asks for countable union and intersection.
\end{defn}

From now on we will assume $\A$ is by default a $\sigma$-algebra. Obviously that the power set $\wp(X)$ is a $\sigma$-algebra.

Given a $\sigma$-algebra $\A$ on $X$, the couplet $(X,\mathcal{A})$ is called a \df{measurable space}, a space on which we can possibly attach a measure. Given a measurable space $(X,\A)$, we call a set $E$ is $\A$-measurable if $E\in \A$.

Also in analysis, ``$\sigma$'' means countable union while ``$\delta$'' means countable intersection. An \df{$F_{\sigma}$ set} is a countable union\footnote{\emph{somme} in French} of closed\footnote{\emph{ferm√©} in French} sets, while a \df{$G_\delta$ set} is a countable intersection\footnote{\emph{Durchschnitt} in German} of open\footnote{\emph{Gebiet} in German} sets.

\begin{defn}
    Within $X$, given a family of subsets $\mathcal{S}$, the smallest $\sigma$-algebra containing $\mathcal{S}$ is called the \df{$\sigma$-algebra generated by} $\mathcal{S}$, denoted by $\sigma(\mathcal{S})$.

    Similar definitions hold for other types of structures.
\end{defn}
Remember the phrase ``the generated is the smallest'', and this should indicate how some proofs should proceed.

Check that the intersection of a family of algebras/$\sigma$-algebras is an algebra/$\sigma$-algebra. Note that the union is not.

If $X$ is a topological space, then the Borel $\sigma$-algebra $\B_X$ is the $\sigma$-algebra generated by all open sets. One can of course replace the ``open'' here by ``close''.

If $X = \R$ with the standard Euclidean topology, then $\B_\R$ is generated  
\begin{itemize}
    \item by open intervals (or closed), 
    \item by left-open right-closed intervals (or the other way around), 
    \item by open rays $\{(a,\infty):a\in\R\}$ (or the other way around),
    \item or by close rays $\{[a,\infty):a\in\R\}$ (or the other way around).
    \item One may replace the endpoints of intervals by rationals as well.
\end{itemize}

The first bullet point boils down the fact that an open set in $\R$ can always be written into the disjoint union of a countable number of open intervals. The proof of this requires us to show that 

\begin{xca}
    Given a set $U$ open in $\R$. The relationship $\sim$ given by $x \sim y$ if $[x \land y, x \lor y] \subseteq U$ is an equivalence relation.
\end{xca}
The theorem is of significant importance throughout measure theory, and is key to the construction of Lebesgue measure on the real line that we will see soon. The notations $x \land y$ and $x \lor y$ are shorthand for $\min\{x,y\}$ and $\max\{x,y\}$. We will use this later more often.

\begin{defn}
     A \df{measure} $\mu$ on $(X,\A)$ is a function $\mu\colon\A\to[0,\infty]$ such that \begin{enumerate}
         \item $\mu(\emptyset) = 0$;
         \item $\mu$ is \df{$\sigma$-additive}, i.e., for a sequence of pairwise disjoint sets $\{E_n\}_{n=1}^\infty \subseteq \A$ (and hence $\cup_n E_n \in \A$), we have  \[
            \mu\biggl(\bigcup_{n=1}^\infty E_n\biggr) = \sum_{n=1}^\infty \mu(E_n).
         \]
     \end{enumerate}
\end{defn}

From now on we assume by default that $\mu$ is a measure. The triplet $(X,\A,\mu)$ is called a ``measure space''.

A measure $\mu$ on $(X,\A)$ is a \df{probability measure}\footnote{Why use this name? Because the probability of the entire sample space should be 1.} if $\mu(X) = 1$; $\mu$ is \df{finite} if $\mu(X) < \infty$; $\mu$ is \df{$\sigma$-finite} if $X$ can be written as a countable union of measurable sets $A_n \in \A$, each of which is of finite measure. Note for a $\sigma$-finite measure, we can replace this countable collection of finite-measure sets that make up $X$ by an increasing sequence of finite-measure sets. We may even further assume that the sets are mutually disjoint. These assumption can be handy in some proofs.

It is clear that probability measure is a finite measure, which is in turn a $\sigma$-finite measure.

A $\sigma$-finite measure means it is a normal kind of measure. The Lebesgue measure that we will rigorously see soon, for example, is $\sigma$-finite. Some major results in measure theory, for example the Fubini--Tonelli theorem (see \cref{sec:prod-integrate}), is only true for $\sigma$-finite measure spaces. A measure that is not $\sigma$-finite is considered, in some sense, a little pathological.

Below are some important basic properties about measures that are used all the time.
\begin{prop}\label{prop:basic-properties-measure}
    We have the following properties about a measure $\mu$ on $(X,\A)$.
    \begin{enumerate}
        \item monotonicity: for $A,B\in \A$, \[
            A\subseteq B \implies \mu(A)\leq \mu(B);
        \]
        \item $\sigma$-subadditivity: for possibly intersecting sets\footnote{Notice there is no such condition in $\sigma$-additivity that we mentioned previously.} $\{E_n\}_{n=1}^\infty \subseteq \A$, \[
            \mu\biggl(\bigcup_{n=1}^\infty E_n\biggr) \leq \sum_{n=1}^\infty \mu(E_n).
        \]
        \item continuity from below: for a sequence of sets $\{E_n\}_{n=1}^\infty \subseteq \A$ that increases to $E$, we have \[
            \mu(E_n) \uparrow \mu(E).
        \]
        \item continuity from above (when the first set is of finite measure): for a sequence of sets $\{E_n\}_{n=1}^\infty \subseteq \A$ with $\mu(E_1)<\infty$ and $E_n \downarrow E$, we have \[
             \mu(E_n) \downarrow \mu(E).
        \]
    \end{enumerate}
\end{prop}
All these properties above require the famous disjointification trick to prove: we partition the sets in question into pairwise disjoint pieces, and then use $\sigma$-additivity of the measure.

Now we discuss two important examples of measure extremely useful in application\footnote{In this note we will avoid going deep into facts/examples/counterexmaples that are ultimately not very useful in practice. One such ``useless'' example that is often mentioned here is the countable-cocountable measure on an uncountable set. One may also list the collection of all countable and cocountable sets as an example of a $\sigma$-algebra earlier, but we have omitted for the same reason. Some results of greater generality and particular examples add further insight to the subject matter and help our understanding, but in many situations this is not the case.}.

The first one is the \df{counting measure}. Consider the measurable space $\bigl(X,\wp(X)\bigr)$. The function $\mu\colon \wp(X) \to [0,\infty]$ given by $\mu(E) = \abs{E}$ is a measure. Basically it counts how many elements are in each subset of $X$.

The second one is the \df{Dirac measure/point mass}. Given $(X,\A)$ and some $x\in X$, we define the function $\delta_X\colon \A \to \{0,1\}$ given by \[
    \delta_x(A) = \begin{cases}
        1 & \text{if } x \in A, \\
        0 & \text{if } x \not\in A.
    \end{cases}
\]
This is clearly a probability measure. Notice its difference from the indicator function. The point mass $\delta_x(A)$ takes in a set and spits out $1$/$0$, while the corresponding indicator $\ind_A(x)$ takes in a point and spits out $1$/$0$.

We end this section with two additional elementary results about measures, which are simple consequences from \cref{prop:basic-properties-measure}. These two results are important in probability theory (especially the second one), but both are indeed purely measure-theoretic.
\begin{cor}[(Upper and lower semicontinuity of measures)]
    For $\{E_n\}_n \subseteq \A$, we have \[
        \mu\bigl(\liminf_n E_n\bigr) \leq \liminf_n \mu(E_n).
    \]
    If in addition $\mu$ is finite, then \[
        \limsup_n \mu(E_n) \leq \mu\bigl(\limsup_n E_n\bigr).
    \]
\end{cor}

\begin{namedthm}[Borel--Cantelli lemma, part I]
    For $\{E_n\}_n \subseteq \A$, assume $\sum_{n} \mu(E_n) <\infty$, then \[
        \mu\bigl(\limsup_n E_n\bigr) = 0.
    \]
\end{namedthm}

Given $(X,\A,\mu)$, a subset $E\subseteq X$ is called a \df{null set}
if there is $B\in\mathcal{A}$ such that $E\subseteq B$ and $\mu(B)=0$.
If $\A$ contains all these null sets, then the measure space is \df{complete}.
The \df{completion} $\overline{\A}$ is the smallest $\sigma$-algebra containing $\A$ such that $(X,\overline{\mathcal{A}},\bar{\mu})$, where $\bar{\mu}$ is a measure on $\overline{\A}$ such that $\bar{\mu}(B)=\mu(B)$ for all $B\in\A$ (i.e., extends $\mu$ on $\A$).

$\overline{\A}$ is unique: let 
\[
\overline{\A}=\{E\cup F:E\in\A\text{ and }F\subseteq N\text{, where }N\text{ is a null set}\},
\]
and the measure $\bar{\mu}$ such that $\bar{\mu}(E\cup F)=\mu(E)$
is the unique extension of $\mu$ from $\A$ to $\overline{\A}$.

\subsection{Two tools from set theory}
\begin{defn}
A \df{$\pi$-system} on $\Omega$ is a nonempty collection of subsets of $\Omega$ that is closed under finite intersections.

A \df{$\lambda$-system} $\mathcal{L}$ on $\Omega$ is a collection of subsets of $\Omega$ such that 
\begin{enumerate}
    \item $\Omega\in\mathcal{L}$; 
    \item if $A,B\in\mathcal{L}$ and $A\subseteq B$, then $B-A\in\mathcal{L}$; (closed under proper differences)
    \item if $A_{n}\in\mathcal{L}$ and $A_{n}\uparrow A$ then $A\in\mathcal{L}$. (closed under ascending countable unions)
\end{enumerate}
\end{defn}
\begin{defn}
    A \emph{monotone class} on $X$ is a collection of subsets of $X$ that is closed under ascending countable unions and descending countable intersections.
    
\end{defn}
\begin{namedthm}[Dynkin's $\pi$-$\lambda$ theorem]
     Within $\Omega$, if $\mathcal{P}$ is a $\pi$-system that is contained in a $\lambda$-system $\mathcal{L}$, then $\sigma(\mathcal{P})\subseteq\mathcal{L}$.
\end{namedthm}
\begin{namedthm}[Monotone class theorem]
     Given an algebra $\A_0$ of sets, then the monotone class $\mathcal{M}$ generated by $\A_0$ coincides with the $\sigma$-algebra $\sigma(\A_0)$ generated by $\A_0$.
\end{namedthm}

We do not prove these results in this note; they are very complicated and not very interesting in the end. ``The generated is the smallest'' is the main idea behind these proofs though.

\begin{namedthm}[Coincidence criterion]
    Let $\mu_1$ and $\mu_2$ be two measures on $(X,\A)$. Suppose we can find a $\pi$-system $\mathcal{K}$ on which the two measures agree, and $\sigma(\mathcal{K}) = \A$.

    If $\mu_1(X) = \mu_2(X) < \infty$ (for example, both are probability measures), then the two measures agree on the entire $\A$.

    More generally, if there exists $\{A_n\} \subseteq \mathcal{K}$ such that $A_n \uparrow X$ and \[
        \mu_1(A_n) = \mu_2(A_n) <\infty \text{ for all }n\in \N,
    \] then the two measures agree on the entire $\A$.
\end{namedthm}

\subsection{Extension theorems}
\begin{namedthm}[Carath√©odory's theorem]
    Given an outer measure $\mu^{*}$ on $X$, then the collection of $\A$ of $\mu^{*}$-measurable sets is in fact a $\sigma$-algebra on $X$. Let $\mu=\mu^{*}|_{\mathcal{A}}$, then $\mu$ is a measure. Also the $\sigma$-algebra $\A$ contains all the null sets, i.e., $(X,\A,\mu)$ is complete.
\end{namedthm}

\begin{proof}
$\A$ is clearly closed under complements. We then check $\A$ is an algebra (the union of two sets in $\A$ is still in $\A$), and show $\mu^{*}$ is finitely additive on $\A$.

We wish to extend finite additivity to countable additivity. We let
$B_{n}=\cup_{j=1}^{n}A_{j}$ and $B=\cup_{j=1}^{\infty}A_{j}$. For
any $E$, we may conclude that 
\[
\mu^{*}(E\cap B_{n})=\sum_{j=1}^{n}\mu(E\cap A_{j}).
\]
It follows that $\mu^{*}(E)\geq\sum_{j=1}^{n}\mu^{*}(E\cap A_{j})+\mu(E\cap B^{\mathrm{c}}).$
Take $n\to\infty$ we may conclude 
\begin{align*}
\mu^{*}(E) & \geq\sum_{j=1}^{\infty}\mu^{*}(E\cap A_{j})+\mu^{*}(E\cap B^{\mathrm{c}})\\
 & \geq\mu^{*}\Bigl(\bigcup_{j=1}^{\infty}(E\cap A_{j})\Bigr)+\mu^{*}(E\cap B^{\mathrm{c}})\\
 & =\mu^{*}(E\cap B)+\mu^{*}(E\cap B^{\mathrm{c}})\geq\mu^{*}(E).
\end{align*}
It follows that $B\in\A$, and if we let $E=B$, the first inequality
(which is an equality) gives countable additivity.

It is easy to show $\A$ contains all $\mu^{*}$-null sets: for $N$
such that $\mu^{*}(N)=0$, for any $E$ we have 
\[
\mu^{*}(E)\leq\mu^{*}(E\cap N)+\mu^{*}(E\cap N^{\mathrm{c}})\leq\mu^{*}(E\cap N^{\mathrm{c}})\leq\mu(E).\qedhere
\]
\end{proof}

\begin{namedthm}[Carath√©odory's extension theorem]
    For algebra $\A_{0}$ on $X$ and its premeasure
$\mu_{0}$, let 
\[
\mu^{*}(E)=\inf\biggl\{\sum_{i=1}^{\infty}\mu_{0}(A_{i}):E\subseteq\bigcup_{i=1}^{\infty}A_{i}\text{, where every }A_{i}\in\A_{0}\biggr\}
\]
for all $E\subseteq X$. Then (1) $\mu^{*}$ is an outer measure on $X$, and hence by Carath√©odory's theorem it gives a meausure space
$(X,\sigma(\A_{0}),\mu)$; (2) $\mu^{*}|_{\A_{0}}=\mu_{0}$; (3) every
set in $\A_{0}$ is $\mu^{*}$-measurable; (4) if $\mu_{0}$ is $\sigma$-finite,
then $\mu$ in (1) is the unique extension of $\mu_{0}$ from $\A_{0}$
to $\sigma(\A_{0})$.
\end{namedthm}

\begin{proof}
When proving $\mu^{*}(E)\geq\mu_{0}(E)$ in (2), consider the disjoint
sets $B_{n}=E\cap(A_{n}-\cup_{i=1}^{n-1}A_{i})$. Then $\cup_{n=1}^{\infty}B_{n}=E$,
which implies $\sum_{n=1}^{\infty}\mu_{0}(A_{n})\geq\sum_{n=1}^{\infty}\mu_{0}(B_{n})=\mu_{0}(E)$.
Then take infimum. (3) is fairly straightforward from definition.

To prove (4), let measure $\nu$ be another extension. Consider $E\in\sigma(\A_{0})$
and $\{A_{i}\}_{i=1}^{\infty}\subseteq\A_{0}$ that covers $E$, we
have 
\[
\nu(E)\leq\sum_{i=1}^{\infty}\nu(A_{i})=\sum_{i=1}^{\infty}\mu_{0}(A_{i}).
\]
Take infimum and we get $\nu(E)\leq\mu(E)$.

Now let $A=\cup_{i=1}^{\infty}A_{i}$, then 
\[
\mu(A)=\lim_{n\to\infty}\mu(\cup_{i=1}^{n}A_{i})=\lim_{n\to\infty}\nu(\cup_{i=1}^{n}A_{i})=\nu(A).
\]
If $\mu(E)<\infty$, then for any $\epsilon>0$ we may choose $\{A_{i}\}_{i=1}^{\infty}$
such that $\mu(A-E)<\epsilon$. It follows that 
\[
\mu(E)\leq\mu(A)=\nu(A)=\nu(E)+\nu(A-E)<\nu(E)+\epsilon.
\]
 Therefore $\mu(E)=\nu(E)$.

Now suppose we have $X=\cup_{j=1}^{\infty}B_{j}$ such that $\mu_{0}(B_{j})<\infty$
and that the $B_{j}$'s are pairwise disjoint. Then for $E\in\sigma(\A_{0})$,
we have 
\[
\mu(E)=\sum_{j=1}^{\infty}\mu(E\cap B_{j})=\sum_{j=1}^{\infty}\nu(E\cap B_{j})=\nu(E),
\]
where the second equality follows from what we have previously.
\end{proof}

\subsection{Lebesgue measure}


\section{Measurable functions and integration}
\subsection{Measurable functions}
\begin{namedthm}[Simple function approximation]
    Given $f \in L^+(X,\A)$, there exists a sequence of nonnegative simple functions $\{s_n\}_{n=1}^\infty$ such that $s_n \uparrow f$ pointwise. Furthermore $s_n \to f$ uniformly on any set on which $f$ is bounded.
\end{namedthm}

Note that the ``furthermore'' part essentially means that every nonnegative bounded measurable function is the increasing uniform limit of nonnegative simple functions.
\subsection{Nonnegative Lebesgue integrals}
\begin{namedthm}[Monotone convergence theorem]
    If $\{f_n\} \subseteq L^+$ such that $f_n \uparrow f$ , then \[
        \int f = \lim_n \int f_n
    \]
\end{namedthm}
Note $f_n \uparrow f$ implies $f = \sup_n f_n$ and is thus measurable. Hence $\int f$ makes sense.
\begin{namedthm}[Fatou's lemma]
    Let $\{f_n\}\subseteq L^+$, then \[
        \int \bigl(\liminf_n f_n\bigr) \leq \liminf_n \int f_n
    \]
\end{namedthm}

\subsection{Signed Lebesgue integrals}
\begin{namedthm}[Lebesgue's dominated convergence theorem]
    Let $\{f_n\}\subseteq L^1$. If 
    \begin{enumerate}
        \item $f_n \to f$ pointwise a.e., [limit]
        \item and there exists some nonnegative $g \in L^1$ such that $\abs{f_n} \leq g$ a.e.\ for all $n$, [bound]
    \end{enumerate}
    then $f \in L^1$ with \[
            \int f = \lim_n \int f_n
    \]
\end{namedthm}
\begin{namedthm}[Bounded convergence theorem]
    Let $\mu$ be finite.
\end{namedthm}

\subsection{Connections to the Riemann theory}
\subsection{Littlewood's second and third principles}
\begin{namedthm}[Egoroff's theorem]
    
\end{namedthm}
\begin{namedthm}[Luzin's theorem]
    
\end{namedthm}
\subsection{Modes of convergence}
\begin{defn}
    We say $f_n \to f$ 
    \begin{itemize}
        \item \df{almost everywhere} (a.e.) if \[
            \mu\{x: \lim_n f_n(x) = f(x)\}^\cpl = 0.
        \]
        \item \df{in $L^p$} if \[
            \int \abs{f_n - f}^p \to 0
        \]
        \item \df{in measure} if for any $\epsilon > 0$, \begin{equation} \label{eq:in-measure}
            \lim_n \mu\{x : \abs{f_n(x) - f(x)} > \epsilon\} = 0.
        \end{equation}
        \item \df{Cauchy in measure} if for any $\epsilon > 0$, there exists $N \in \N$ such that for all $m > n \geq N$, \begin{equation} \label{eq:Cauchy-in-measure}
            \mu\{x:\abs{f_n(x) - f_m(x)} > \epsilon \} < \epsilon
        \end{equation}
    \end{itemize}
    Note that the ``$>$'' in both \eqref{eq:in-measure} and \eqref{eq:Cauchy-in-measure} can be replaced by ``$\geq$'', obviously.
\end{defn}
\begin{exa}
    
\end{exa}

\subsection{Uniformly integrable functions}
\begin{namedthm}[Vitali's convergence theorem]
    
\end{namedthm}
\subsection{Continuity and differentiability of parametrized functions}

\subsection{Image measures}
Consider a measure space $(X,\mathcal{M},\mu)$ and a measurable space $(Y,\mathcal{N})$. If we have an $(\mathcal{M},\mathcal{N})$-measurable function $\phi\colon X \to Y$, then we can define a function $\mu_{*}\colon \mathcal{N} \to [0,\infty]$ given by \[
    \mu_{*}(E) =  \mu(\phi^{-1}E)
\] for all $E\in \mathcal{N}$. This turns out to a measure on $(Y,\mathcal N)$, and we call this the \df{image/pushforward measure of $\mu$ by $\phi$}, denoted by $\mu_*\phi$ or $\mu_{\#}\phi$.

Image measure characterizes change of variables, which is of basic importance in mathematics. We will use image measures later in \cref{sec:cov,sec:polar,sec:rv-expec}.

We state the main result below.
\begin{prop}
    Under the conditions stated above, let $g\in L^+(Y,\mathcal{N})$. Then we have \begin{equation}
        \int_X g\bigl(\phi(x)\bigr) \,d\mu(x) = \int_Y g(y) \,d\mu_*(y). \label{eq:image-m}
    \end{equation}
\end{prop}
\begin{proof}
    When $g = \ind_E$ for $E \in \mathcal{N}$, we have \[
        \mathrm{LHS} = \mu\{x : \phi(x) \in E\} = \mu(\phi^{-1} E) \quad \text{and} \quad 
        \mathrm{RHS} = \mu_{*}(E).
    \] Now extend this to simple functions and then nonnegative functions.
\end{proof}
Of course the result \eqref{eq:image-m} continues to hold for $g \circ \phi \in L^1(X,\mathcal{M},\mu)$.

\section{Product spaces}
\subsection{Construction of product measures}

Define $\B^n$ to be the product $\sigma$-algebra of $n$ Borel $\sigma$-algebra on the reals ($\B_{\R}$). Then $\B^n$ is also the $\sigma$-algebra generated by all open sets in $\R^n$.
\subsection{Integration on product spaces} \label{sec:prod-integrate}
\begin{namedthm}[Tonelli's theorem]
    
\end{namedthm}
\begin{namedthm}[Fubini's theorem]
    
\end{namedthm}
\subsection{Change of variables} \label{sec:cov}
\subsection{Gamma functions and polar coordinates} \label{sec:polar}

\section{Structure of measures}
\subsection{Signed measures}

\begin{defn} 
    Let $\mu$ and $\nu$ be two positive/signed/complex measures on $(X, \A)$. We say $\mu$ and $\nu$ are \df{mutually singular}, denoted by $\mu \perp \nu$, if $X$ can be partitioned into two measurable subsets $A$ and $B$, such that \[
        \mu(B) = 0 \quad \text{and} \quad \nu(A) = 0,
    \] or equivalently, \[
        \mu(E) = \mu(E\cap A) \quad \text{and} \quad \nu(E) = \nu(E \cap B).
    \]
\end{defn}
\begin{defn} \label{def:abs-cont}
     Let $\mu$ be a positive measure and $\nu$ be a positive/signed/complex measure on $(X, \A)$. We say $\nu$ is \df{absolutely continuous} with respect to $\mu$, denoted by $\nu \ll \mu$, if for all $E\in \A$, \begin{equation} \label{eq:def-abs-cont}
         \mu(E) = 0 \implies \nu(E) = 0.
     \end{equation}
        
    To define absolute continuity $\nu \ll \mu$ for signed/complex $\mu$, we change \eqref{eq:def-abs-cont} to \begin{equation} \label{eq:def-abs-cont-sign-cplx}
        \abs{\mu}(E) = 0 \implies \nu(E) = 0.
    \end{equation} This is a definition not used much in practice.
\end{defn}
One should check that $\nu \ll \mu$ if and only if $\abs{\nu} \ll \mu$.


\subsection{Hahn and Jordan decomposition}
\begin{namedthm}[Hahn decomposition]
    Let $\mu$ be a signed measure on $(X,\A)$. Then $X$ has a partition into $P$ and $N$ such that $P$ is a positive set and $N$ is a negative set.

    Furthermore, if $P'$ and $N'$ is another such partition, then $P \triangle P' = N \triangle N'$ is $\mu$-null.
\end{namedthm}
\begin{namedthm}[Jordan decomposition]
    Let $\mu$ be a signed measure on $(X,\A)$. Then there exist unique two finite positive measures $\mu^+$ and $\mu^-$ on $(X,\A)$ such that \[
        \mu = \mu^+ - \mu^- \quad \text{and} \quad \mu^+ \perp \mu^-.
    \]
\end{namedthm}
\subsection{Radon--Nikodym theorem and Lebesgue decomposition}
Depending on what kind of measures we are looking at, there exists multiple versions of the Radon--Nikodym theorem. The following version is the most basic one in practice. It considers a pair of $\sigma$-finite and finite measures.
\begin{namedthm}[Radon--Nikodym theorem] \label{thm:Radon-Nikodym}
    Let $\mu$ be a $\sigma$-finite measure and $\nu$ be a finite measure on $(X,\A)$, where $\nu \ll \mu$. Then there exists an $\A$-measurable function $f$ such that \[
        \nu(E) = \int_E f \,d\mu \quad \text{for all }E\in \mathcal{A}.
    \]
    Furthermore this $f$ is nonnegative and unique in $L^1(X,\A,\mu)$.

    If the $\nu$ above is given as a signed/complex measure instead, then the same conclusions still hold after dropping $f$ is nonnegative.
\end{namedthm}
Our $f$ here is called the \df{density/Radon--Nikodym derivative} of $\nu$ with respect to $\mu$, denoted by $d\nu/d\mu$.

It suffices to prove the more general decomposition result.
\begin{namedthm}[Lebesgue decomposition]\label{thm:Leb-decomp}
     Let $\mu$ be a $\sigma$-finite measure and $\nu$ be a finite measure on $(X,\A)$. Then 
     \begin{enumerate}
         \item \label{enu:decomp} there exist two unique finite measures $\nu_a$ and $\nu_s$ on $(X,\mathcal{A})$ such that \[
            \nu = \nu_{a} + \nu_{s}\text{, where }\nu_a \ll \mu \text{ and } \nu_s \perp \mu;
         \]
         \item \label{enu:derivative} there exists an $\A$-measurable function $f$, nonnegative and unique in $L^1(X,\A,\mu)$, such that \[
            \nu_a(E) = \int_E f \,d\mu \quad \text{for all }E\in \mathcal{A}.
         \]
     \end{enumerate}
\end{namedthm}
We summarize two standard proofs of this theorem. The first of which uses results from Hilbert spaces, while the second one is based on variational principles.
\begin{proof}[Proof 1 of Lebesgue decomposition, using Hilbert spaces]
    
\end{proof}
\begin{proof}[Proof 2 of Lebesgue decomposition, using variational principles]
    
\end{proof}

We briefly discuss Lebesgue decomposition for other types of measures below.
\begin{itemize}
    \item If $\nu$ is given as a signed/complex measure instead, then ``finite'' becomes ``signed''/``complex'' in conclusion~\ref{enu:decomp}, and we drop ``nonnegative'' in conclusion~\ref{enu:derivative}.
    \item If $\nu$ is given as a $\sigma$-finite measure instead, then in conclusion~\ref{enu:decomp} $\nu_a$ and $\nu_s$ become $\sigma$-finite, while in conclusion~\ref{enu:derivative} $f$ becomes nonnegative real-valued\footnote{i.e., $f$ takes values in $[0,\infty)$.}, and is unique a.e.
    \item Conclusion~\ref{enu:decomp} continues to hold if $\mu$ and $\nu$ are both signed or complex. Recall the definition of absolute continuity in this case from \eqref{eq:def-abs-cont-sign-cplx}.
\end{itemize}
\begin{rem}
    % This paragraph is borrowed from \cite[Section 3.2]{Bogachev_2007}.
    
    % Given a $\sigma$-finite positive measure $\mu$ on $(X,\A)$, then every finite nonnegative measurable function (not necessarily integrable) defines the $\sigma$-finite positive measure $d\nu_{a} = f d\mu.$ Since $X$ can be written as $\cup_{n=1}^\infty X_n$, where each $X_n$ is $\mu$-finite. 
    If $\nu$ is given as a signed measure instead, then write $\nu = \nu^+ - \nu^-$, and then use the above version of \nameref{thm:Leb-decomp} to write
    
    For each $n\in \N$, set $\nu_n (E) = \nu(E\cap X_n)$ for all $E\in \A$ and get a finite measure $\nu_n$. Now apply \nameref{thm:Leb-decomp} for finite $\nu$ above
\end{rem}
\subsection{Differentiation}
\subsection{Functions of bounded variations}
\subsection{Absolutely continuous functions}
\begin{defn}
    Let $I \subseteq \R$ be an interval. A function $f\colon I\to \R$ is absolutely continuous if for all $\epsilon > 0$, there exists $\delta > 0$ such that \[
        \sum_{i=1}^n (b_i - a_i) < \delta \implies \sum_{i=1}^n \abs{f(b_i) - f(a_I)} <\epsilon
    \] holds for any finite family of pairwise disjoint open intervals $\{(a_i,b_i)\}_{i=1}^n$ contained in $I$.
\end{defn}
\subsection{Fundamental theorem of calculus}

\section{Lebesgue spaces}
\subsection{When \texorpdfstring{$1 \leq p < \infty$}{1 <= p < infinity}}

\subsection{When \texorpdfstring{$p = \infty$}{p = infty}}

\subsection{The Hilbert space \texorpdfstring{$L^2$}{L2}}

\subsection{Dual spaces}

\part{Probability}
\section{Probability spaces and distributions}

\subsection{Gaussian measures}
\begin{namedthm}[Kolmogorov‚Äôs extension theorem]
    
\end{namedthm}

\section{Random variables and expected values}\label{sec:rv-expec}
\begin{defn}
    The \df{(probability) density function} of a random variable $X$ is the Radon--Nikodym derivative $d\mu/dm$ of the probability distribution with respect to the Lebesgue measure.
\end{defn}

\subsection{Independence}

\section{Convergence of probability measures}

\section{Conditional expectations and martingales}
\begin{defn}
    Let $\E \abs{X} < \infty$, and $\G$ be a sub-$\sigma$-field of $\F$. Define the \df{conditional expectation of $X$ given $\G$} to be the random variable $Y$ satisfying \begin{enumerate}
        \item $Y$ is $\G$-measurable; 
        \item $\E(Y \ind_{G}) = \E(X \ind_G)$ for all $G \in \G$.
    \end{enumerate}
    This $Y$ is denoted by $\E(X \giv \G)$.
\end{defn}

We first show that the above definition makes sense from a purely measure-theoretic point of view, and is unique a.s.
Notice that the function $\nu\colon \mathcal{G} \to \R$ given by \begin{equation} \label{eq:cond-expec-signed-meas}
    \nu(G) = \E(X\ind_G) = \int_G X \,dP
\end{equation} is a signed measure, and $\nu \ll P$. Therefore by the \nameref{thm:Radon-Nikodym} for a signed measure and a finite positive measure, there exists a random variable $Y$, unique in $L^1(\Omega,\G,P)$, such that \[
    \nu(G) = \int_G Y \,dP = \E(Y\ind_G)
\] for all $G\in \G$.

% Note that there does not exist a version of conditional expectation $\E(X\giv \G)$ defined specifically for nonnegative $X$. This is because the $\nu$ we defined in \eqref{eq:cond-expec-signed-meas} may become possibly infinite. We have discussed previously that there does not exist a nice Radon--Nikodym theorem for a general infinite measure $\nu$.

\begin{defn}
    Define the conditional probability of $A \in \F$ given a sub-$\sigma$-field $\G$ of $\F$ to be $\E(\ind_A \giv \G)$, which we denote by $P(A\giv \G)$.
\end{defn}

When $X = \ind_A$, the $\nu(G)$ in \eqref{eq:cond-expec-signed-meas} now becomes $P(A\cap G)$. The conditional probability $P(A \giv \G)$ is therefore the Radon--Nikodym derivative of the probability measure $\nu$ (that takes the information $\G$ into account) with respect to the original probability measure $P$.

\newpage
\printbibliography
\end{document}