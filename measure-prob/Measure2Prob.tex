% \documentclass[10pt]{article}
% \usepackage[T1]{fontenc}
% \usepackage[margin=1in]{geometry}
% \usepackage{amsmath,amssymb,amsthm}
% \usepackage{mathtools}
% \usepackage{tikz-cd}
% \usepackage{enumitem}
% \usepackage{setspace,microtype}
% \usepackage{soul,mdframed}
% \usepackage[dvipsnames]{xcolor}
% \usepackage{imakeidx}
% \usepackage{xifthen}
% \usepackage[pdfusetitle,bookmarks,bookmarksnumbered,bookmarksopen,bookmarksopenlevel=1,colorlinks,
% citecolor=CornflowerBlue,urlcolor=CornflowerBlue,linkcolor=BurntOrange]{hyperref}
% \usepackage[capitalize]{cleveref}
% \usepackage[all]{hypcap}

% \usepackage{titlesec}
% \titleformat*{\section}{\Large}
% \titleformat*{\subsection}{\large}

% \usepackage{titletoc}
% \contentsmargin{2.4em}
% \titlecontents{section}
% [2em] 
% {\addvspace{.5\baselineskip}}
% {\contentslabel{2em}}
% {\hspace*{-2em}}
% {\hfill\contentspage}
% \titlecontents{subsection}
% [4.8em]
% {}
% {\contentslabel{2.8em}}
% {\hspace*{-2.8em}}
% {\titlerule*[1pc]{.}\contentspage}

% \makeindex[title=List of Definitions]

% % no parentheses
% \newtheoremstyle{plain-star}{\topsep}{\topsep}{}{}{\sffamily}{.}{5pt plus 1pt minus 1pt}{\thmnumber{#2 }\thmname{#1}\thmnote{ #3}}

% \newtheoremstyle{definition-star}{\topsep}{\topsep}{}{}{\sffamily}{.}{5pt plus 1pt minus 1pt}{\thmnumber{#2 }\thmname{#1}\thmnote{ #3}}

% \newtheoremstyle{remark-star}{.5\topsep}{.5\topsep}{}{}{\itshape\sffamily}{.}{5pt plus 1pt minus 1pt}{\thmnumber{#2 }\thmname{#1}\thmnote{ #3}}

% \renewcommand\thesubsection{\thesection.\Alph{subsection}}
% \numberwithin{equation}{section}
% \theoremstyle{plain-star}
% \newtheorem{thm}[equation]{Theorem}
% \newtheorem*{thm*}{Theorem}
% \newtheorem{prop}[equation]{Proposition}
% % \newtheorem*{prop*}[equation]{Proposition}
% \newtheorem{fact}[equation]{Fact}
% \newtheorem{lem}[equation]{Lemma}
% \newtheorem{cor}[equation]{Corollary}
% \theoremstyle{definition-star}
% \newtheorem{defn}[equation]{Definition}
% \newtheorem{exa}[equation]{Example}
% \newtheorem{xca}[equation]{Exercise}
% \theoremstyle{remark-star}
% \newtheorem{rem}[equation]{Remark}
% \newtheorem*{rem*}{Remark}

% \newenvironment{sketch}[1][Sketch]{\begin{proof}[#1]\renewcommand*{\qedsymbol}{$\triangle$}}{\end{proof}}

% \makeatletter
% \newcommand\thmsname{Theorem}
% \newcommand\nm@thmtype{theorem}
% \theoremstyle{plain-star}
% \newtheorem{namedtheorem}[equation]{\thmsname}
% \newenvironment{namedthm}[1][Undefined Theorem Name]{
%     \ifx{#1}{Undefined Theorem Name}
%     \renewcommand\nm@thmtype{theorem}
%     \else\renewcommand\thmsname{#1}
%     \renewcommand\nm@thmtype{namedtheorem}
%     \fi
%     \begin{\nm@thmtype}\def\@currentlabelname{#1}}
%     {\end{\nm@thmtype}}

% \newtheorem*{namedtheorem*}{\thmsname}
% \newenvironment{namedthm*}[1][Undefined Theorem Name]{
%     \ifx{#1}{Undefined Theorem Name} \renewcommand\nm@thmtype{theorem*}
%     \else\renewcommand\thmsname{#1}
%     \renewcommand\nm@thmtype{namedtheorem*}
%     \fi
%     \begin{\nm@thmtype}}
%     {\end{\nm@thmtype}}
% \makeatother

% % \renewcommand{\arraystretch}{1.2}

% \setlength{\parskip}{0em} % default parskip
% \setlist{listparindent=\parindent,parsep=0pt,left=\parindent} % indentation and separation between list paragraphs
% \setlist[enumerate,1]{label=(\alph*)}
% \setlist[enumerate,2]{label=(\roman*)}
% \counterwithin*{footnote}{section} %footnote changes based on section
% \mdfdefinestyle{simple}{%
%     innerleftmargin=0pt,
%     innerrightmargin=0pt,
%     innertopmargin=2pt,
%     innerbottommargin=2pt
% }

% \makeatletter
% % \onehalfspacing
% \usepackage{xpatch}
% \xpatchcmd{\env@cases}{1.2}{1.1}{}{}
% \xpatchcmd{\proof}{\itshape}{\normalfont\proofnamefont}{}{}
% \newcommand{\proofnamefont}{\itshape\sffamily}

% \let\@subtitle\@empty % default value
% \protected\def\subtitle#1{\gdef\@subtitle{#1}}
% \def\@maketitle{%
%   \newpage
%   \begin{center}%
%   \let \footnote \thanks
%     {\Large\sffamily \@title \par}% % LARGE
%     {\sffamily \@subtitle \par}% % large
%     \vskip 0.5em%
%     {\lineskip .5em%
%       \begin{tabular}[t]{c}%
%         \sffamily \@author
%       \end{tabular}\par}%
%     {\sffamily \@date}%
%     \vskip -0.5em%
%   \end{center}%
%   \par}
% \makeatother

% \newcommand{\R}{\mathbf{R}}
% \newcommand{\C}{\mathbf{C}}
% \newcommand{\Z}{\mathbf{Z}}
% \newcommand{\N}{\mathbf{N}}
% \newcommand{\Q}{\mathbf{Q}}
% \newcommand{\ind}{\mathbf{1}}
% \renewcommand{\Pr}{P}
% \newcommand{\E}{\mathop{}\!\mathrm{E}}
% \newcommand{\Var}{\operatorname{Var}}
% \newcommand{\Cov}{\operatorname{Cov}}
% \newcommand{\giv}{\,|\,}
% \newcommand{\A}{\mathcal{A}}
% \newcommand{\B}{\mathcal{B}}
% \newcommand{\F}{\mathcal{F}}
% \newcommand{\G}{\mathcal{G}}
% \newcommand{\M}{\mathcal{M}}
% \newcommand{\Mat}{\operatorname{Mat}}
% \renewcommand{\Re}{\operatorname{Re}}
% \renewcommand{\Im}{\operatorname{Im}}
% \newcommand{\ol}[1]{\overline{#1}}
% \newcommand{\eR}{\ol{\R}}
% \newcommand{\cpl}{\mathrm{c}}
% \newcommand{\trp}{\mathrm{T}}
% \newcommand{\la}{\langle}
% \newcommand{\ra}{\rangle}
% \newcommand{\inp}[2]{\langle #1, #2 \rangle}
% \newcommand{\nm}[1]{\lVert #1 \rVert}
% \newcommand{\abs}[1]{\lvert #1 \rvert}
% \newcommand{\tr}{\operatorname{tr}}
% \newcommand{\blank}{\,\cdot\,}
% \renewcommand{\phi}{\varphi}
% % \renewcommand{\implies}{\Rightarrow}
% % \renewcommand{\impliedby}{\Leftarrow}

% % requires xifthen; for automatic/manual indexing
% \newcommand{\df}[2][]{\ifthenelse{\isempty{#1}}{\textit{#2}\index{#2}}{\textit{#2}\index{#1}}}

% \usepackage[backend=biber,style=alphabetic,doi=false,url=false,isbn=false]{biblatex}
% \addbibresource{MP.bib}
% \renewbibmacro{in:}{}

% % disable automatic page designation
% \DeclareFieldFormat{postnote}{#1}


% \title{From Measure to Probability}
% \subtitle{A survey of measure-theoretic results for mathematical probabilists}
% \author{Feng Cheng\thanks{Email: \href{mailto:fecheng@uw.edu}{\texttt{fecheng@uw.edu}}. Affiliation: Department of Mathematics, University of Washington, Seattle, WA 98195, USA.}}
% \date{}

% \begin{document}
% \maketitle

% \tableofcontents
% \newpage

% \phantomsection
% \addcontentsline{toc}{part}{Prologue}
% \part*{\Large Prologue}

% This is the most ambitious writing project undertaken by the author so far as a math student, and he hopes he can finish it in two years. The author, as a probability student, did not excel in his real analysis courses (MATH 202AB at UC Berkeley) during his senior year. To compensate, the author aims to write an extensive and detailed note that surveys through all the major measure theory results of interest to a rigorous-minded mathematical probabilist.

% Part I of this note will be devoted to measure theory in a general setting, while Part II will discuss results in probability spaces built on top of Part I. The author hopes that his commentary and the overall structure of the survey can help the readers (and himself) truly understand both abstract measure theory and probability theory from a measure-theoretic point of view.

% This entire survey will be based on multiple sources, listed in the bibliography page. As the old saying goes, ``if you copy from one book that is plagiarism, but if you copy from ten books that is scholarship.''
% \vspace{1\baselineskip}

% \noindent Shanghai, August 2024 \hfill F.C.
% \newpage

% \part{Measure theory}
% \section{Measure spaces and construction of measures}
% \subsection{Basic setup}
% We let $X$ be a nonempty set in Part I.
% \begin{defn}
%     For $\{A_n\}_{n=1}^\infty\subseteq \wp(X)$, we define \[
%         \limsup_{n \to \infty} A_n = \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty A_m \quad \text{and}\quad \liminf_{n \to \infty} A_n = \bigcup_{n = 1}^\infty \bigcap_{m = n}^\infty A_m.
%     \]
% \end{defn}
% Note $\bigcap$ can be seen as ``for all'' and $\bigcup$ can be seen as ``there exists''. Therefore $\limsup_n A_n$ consists of elements that belong to infinitely many $A_n$'s (spread out across $n \in \N$), while $\liminf_n A_n$ consists of elements that belong to all but finitely $A_n$ (the $n$'s at the beginning). To compare this with the $\limsup$ and $\liminf$ of a sequence of numbers, one may try the following exercise.

% \begin{xca}
%     Show that \begin{align*}
%         \limsup_{n \to \infty}  A_n = A & \iff \limsup_{n \to \infty} \ind_{A_n} = \ind_A, \\
%         \liminf_{n \to \infty}  A_n = A & \iff \liminf_{n \to \infty} \ind_{A_n} = \ind_A.
%     \end{align*}

%     Here $\ind_A\colon X \to \{0,1\}$ given by \[
%         \ind_A(x)= \begin{cases}
%             1 & \text{if } x \in A, \\
%             0 & \text{if } x \not\in A.
%         \end{cases}
%     \]
%     is called the \df{indicator function} (\df[characteristic function (measure theory)]{characteristic function} for analysts who choose to write $\chi_A$).
% \end{xca}

% If $\{A_n\}_{n=1}^\infty$ is an increasing sequence of sets, then \[
%     \liminf_n A_n = \limsup_n A_n = \bigcup_n A_n;
% \] if the sequence is decreasing, then \[
%     \liminf_n A_n = \limsup_n A_n = \bigcap_n A_n.
% \] Also remember that, by De Morgan's Law, \[
%     \limsup_n A_n^\cpl = \bigl(\liminf_n A_n\bigr)^\cpl \quad \text{and}\quad 
%     \liminf_n A_n^\cpl = \bigl(\limsup_n A_n \bigr)^\cpl.
% \]

% Here is another exercise.

% \begin{xca}
%     Consider a sequence of functions $f_n$ that convergences to $f$ pointwise on some set $E$. If we define \[
%         E_{n,\epsilon} = \{x:\abs{f_n(x) - f(x)} < \epsilon\}
%     \] for $\epsilon > 0$ and $n\in \N$, then \[
%         E = \bigcap_{k=1}^\infty \liminf_m E_m^{1/k} = \bigcap_{k=1}^\infty \bigcup_{m=1}^\infty \bigcap_{n\geq m} E_n^{1/k}.
%     \]
% \end{xca}

% \begin{defn}
%     A nonempty collection of subsets of $X$ is an \df{algebra} if \begin{enumerate}
%         \item $\emptyset,X \in \A$;
%         \item closed under complement;
%         \item \label{enu:algebra-finite-union} closed under finite unions and intersections.
%     \end{enumerate}
%     Furthermore, $\A$ is called a \df[sigma-algebra@$\sigma$-algebra]{$\sigma$-algebra} if condition~\ref{enu:algebra-finite-union} asks for countable union and intersection.
% \end{defn}

% An algebra can be constructed from a more basic structure called semialgebra, which we define below.
% \begin{defn}
%     A \df{semialgebra} $\mathcal{E}$ is a collection of sets such that \begin{enumerate}
%         \item \label{enu:cond1-semialgebra}$\emptyset \in \mathcal{E}$;
%         \item closed under finite intersections;
%         \item if $A \in \mathcal{E}$ then $A^\cpl$ is a finite disjoint union of elements in $\mathcal{E}$.
%     \end{enumerate}
% \end{defn}
% Some authors drop condition~\ref{enu:cond1-semialgebra}, while others add the condition that $X \in \mathcal{E}$. But of course there is no essential difference. Now the main result.

% \begin{prop}[{\cite[Proposition~1.7]{folland1999}}]
%     If $\mathcal{E}$ is a semialgebra\footnote{Folland calls this elementary family.}, then all finite disjoint unions of sets in $\mathcal{E}$ form an algebra.
% \end{prop}

% The most important example of a semialgebra is the empty set plus all sets of the form \[
%     (a_1,b_1] \times \dotsb \times (a_d,b_d] \subseteq \R^d,
% \] where $-\infty \leq a_j<b_j \leq \infty$. The finite disjoint unions of half-open half-closed cubes should therefore form an algebra.

% From now on we will assume $\A$ is by default a $\sigma$-algebra. Obviously the largest $\sigma$-algebra on $X$ is the power set $\wp(X)$.

% Given a $\sigma$-algebra $\A$ on $X$, the couplet $(X,\mathcal{A})$ is called a \df{measurable space}, a space on which we can possibly attach a measure. Given a measurable space $(X,\A)$, we call a set $E$ is $\A$-measurable if $E\in \A$.

% Also in analysis, ``$\sigma$'' means countable union while ``$\delta$'' means countable intersection. An \df[F-sigma set@$F_\sigma$ set]{$F_{\sigma}$ set} is a countable union\footnote{\emph{somme} in French} of closed\footnote{\emph{fermé} in French} sets, while a \df[G-delta set@$G_\delta$ set]{$G_\delta$ set} is a countable intersection\footnote{\emph{Durchschnitt} in German} of open\footnote{\emph{Gebiet} in German} sets.

% We know that the preimage of a function $f\colon X \to Y$ is a mapping $f^{-1}\colon \wp(Y) \to \wp(X)$ that preserves unions, intersections, and complements, which are also operations in the definition of a $\sigma$-algebra. The next result makes the relationship between the two explicit. See \cref{sec:measurable-functions} for the use.
% \begin{prop}[{\cite[Lemma 1.3]{Kallenberg_2002}}] \label{prop:induce-s-alg-meas-map}
%     Consider $f\colon X \to Y$, and $\mathcal{M}$ and $\mathcal{N}$ be two respective $\sigma$-algebras on $X$ and $Y$. The preimage $f^{-1}$ induces two $\sigma$-algebras: \begin{enumerate}
%         \item \label{enu:backward-ind-s-alg} $\mathcal{M}' =\{f^{-1}(A) : A \in \mathcal{N}\}$ on $X$, in the backward direction; 
%         \item \label{enu:forward-ind-s-alg} $\mathcal{N}' = \{B \subseteq Y : f^{-1}(B) \in \mathcal{M}\}$ on $Y$, in the forward direction.
%     \end{enumerate}
% \end{prop}

% \begin{defn}
%     Within $X$, given a family of subsets $\mathcal{S}$, the smallest $\sigma$-algebra containing $\mathcal{S}$, i.e., the intersection of all $\sigma$-algebras that contains $\mathcal{S}$, is called the \df[sigma-algebra generated by@$\sigma$-algebra generated by!sets]{$\sigma$-algebra generated by $\mathcal{S}$} , denoted by $\sigma(\mathcal{S})$.

%     Similar definitions hold for other types of structures.
% \end{defn}
% Remember the phrase ``the generated is the smallest'', and this should indicate how some proofs should proceed.

% Check that the intersection of a family of algebras/$\sigma$-algebras is an algebra/$\sigma$-algebra. Note that the union is not.

% If $X$ is a topological space, then the \df[Borel sigma-algebra@Borel $\sigma$-algebra]{Borel $\sigma$-algebra} on $X$, which we denote by $\B_X$ or $\B(X)$, is the $\sigma$-algebra generated by all open sets. One can of course replace the ``open'' here by ``close''.

% If $X = \R$ with the standard Euclidean topology, then $\B_\R$ is generated  
% \begin{itemize}
%     \item by open intervals (or closed), 
%     \item by left-open right-closed intervals (or the other way around), 
%     \item by open rays $\{(a,\infty):a\in\R\}$ (or the other way around),
%     \item or by close rays $\{[a,\infty):a\in\R\}$ (or the other way around).
%     \item One may replace the endpoints of intervals by rationals as well.
% \end{itemize}

% The first bullet point boils down the fact that an open set in $\R$ can always be written into the disjoint union of a countable number of open intervals. The proof of this requires us to show that 

% \begin{xca}
%     Given a set $U$ open in $\R$. The relationship $\sim$ on $U$ given by $x \sim y$ if $[x \land y, x \lor y] \subseteq U$ is an equivalence relation.
% \end{xca}
% The theorem is of significant importance throughout measure theory, and is key to the construction of Lebesgue measure on the real line that we will see soon. The notations $x \land y$ and $x \lor y$ are shorthand for $\min\{x,y\}$ and $\max\{x,y\}$. We will use this later more often.

% \begin{defn}
%      A \df{measure} $\mu$ on $(X,\A)$ is a function $\mu\colon\A\to[0,\infty]$ such that \begin{enumerate}
%          \item $\mu(\emptyset) = 0$;
%          \item $\mu$ is \df[sigma-additive@$\sigma$-additive]{$\sigma$-additive}, i.e., for a sequence of pairwise disjoint sets $\{E_n\}_{n=1}^\infty \subseteq \A$ (and hence $\cup_n E_n \in \A$), we have  \[
%             \mu\biggl(\bigcup_{n=1}^\infty E_n\biggr) = \sum_{n=1}^\infty \mu(E_n).
%          \]
%      \end{enumerate}
% \end{defn}

% From now on we assume by default that $\mu$ is a measure. The triplet $(X,\A,\mu)$ is called a \df{measure space}.

% A measure $\mu$ on $(X,\A)$ is a \df{probability measure}\footnote{Why use this name? Because the probability of the entire sample space should be 1.} if $\mu(X) = 1$; $\mu$ is \df[finite measure]{finite} if $\mu(X) < \infty$; $\mu$ is \df[sigma-finite measure@$\sigma$-finite measure]{$\sigma$-finite} if $X$ can be written as a countable union of measurable sets $A_n \in \A$, each of which is of finite measure. Note for a $\sigma$-finite measure, we can replace this countable collection of finite-measure sets that make up $X$ by an increasing sequence of finite-measure sets. We may even further assume that the sets are mutually disjoint. These assumption can be handy in some proofs.

% It is clear that probability measure is a finite measure, which is in turn a $\sigma$-finite measure. Probability measure is the essential example of a finite measure, because mostly you can normalize the measure of the whole space to $1$.

% A $\sigma$-finite measure means it is a normal kind of measure. The Lebesgue measure that we will rigorously see soon, for example, is $\sigma$-finite. Some major results in measure theory, for example the Fubini--Tonelli theorem (see \cref{sec:prod-integrate}), are only true for $\sigma$-finite measure spaces. A measure that is not $\sigma$-finite is considered, in some sense, a little pathological.

% The following fact will come up a couple of times.
% \begin{fact}
%     Fix some $A \in \A$. The function $\nu\colon \A\to [0,\infty]$ given by $\nu(E) = \mu(E \cap A)$ is still a measure.
% \end{fact}

% Below are some important basic properties about measures that are used all the time.
% \begin{prop}\label{prop:basic-properties-measure}
%     We have the following properties about a measure $\mu$ on $(X,\A)$.
%     \begin{enumerate}
%         \item monotonicity: for $A,B\in \A$, \[
%             A\subseteq B \implies \mu(A)\leq \mu(B);
%         \]
%         \item \df[sigma-subadditivity@$\sigma$-subadditivity]{$\sigma$-subadditivity}: for possibly intersecting sets\footnote{Recall in $\sigma$-additivity the sets must be mutually disjoint.} $\{E_n\}_{n=1}^\infty \subseteq \A$, \[
%             \mu\biggl(\bigcup_{n=1}^\infty E_n\biggr) \leq \sum_{n=1}^\infty \mu(E_n).
%         \]
%         \item continuity from below: for a sequence of sets $\{E_n\}_{n=1}^\infty \subseteq \A$ that increases to $E$, we have \[
%             \mu(E_n) \uparrow \mu(E).
%         \]
%         \item continuity from above (when the first set is of finite measure): for a sequence of sets $\{E_n\}_{n=1}^\infty \subseteq \A$ with $\mu(E_1)<\infty$ and $E_n \downarrow E$, we have \[
%              \mu(E_n) \downarrow \mu(E).
%         \]
%     \end{enumerate}
% \end{prop}
% All these properties above require the famous disjointification trick to prove: we partition the sets in question into pairwise disjoint pieces, and then use $\sigma$-additivity of the measure.

% Now we discuss two important examples of measure extremely useful in application\footnote{In this note we will avoid going deep into facts/examples/counterexmaples that are ultimately not very useful in practice. One such ``useless'' example that is often mentioned here is the countable-cocountable measure on an uncountable set. One may also list the collection of all countable and cocountable sets as an example of a $\sigma$-algebra earlier, but we have omitted for the same reason. Some results of greater generality and particular examples add further insight to the subject matter and help our understanding, but in many situations this is not the case.}.

% The first one is the \df{counting measure}. Consider the measurable space $\bigl(X,\wp(X)\bigr)$. The function $\mu\colon \wp(X) \to [0,\infty]$ given by $\mu(E) = \abs{E}$ is a measure. Basically it counts how many elements are in each subset of $X$.

% The second one is the \df{Dirac measure/point mass}. Given $(X,\A)$ and some $x\in X$, we define the function $\delta_X\colon \A \to \{0,1\}$ given by \[
%     \delta_x(A) = \begin{cases}
%         1 & \text{if } x \in A, \\
%         0 & \text{if } x \not\in A.
%     \end{cases}
% \]
% This is clearly a probability measure. Notice its difference from the indicator function. The point mass $\delta_x(A)$ takes in a set and spits out $1$/$0$, while the corresponding indicator $\ind_A(x)$ takes in a point and spits out $1$/$0$.

% We now introduce two additional elementary results about measures, which are simple consequences from \cref{prop:basic-properties-measure}. These two results are important in probability theory (especially the second one), but both are indeed purely measure-theoretic.
% \begin{cor}[(Upper and lower semicontinuity of measures)]
%     For $\{E_n\}_n \subseteq \A$, we have \[
%         \mu\bigl(\liminf_n E_n\bigr) \leq \liminf_n \mu(E_n).
%     \]
%     If in addition $\mu$ is finite, then \[
%         \limsup_n \mu(E_n) \leq \mu\bigl(\limsup_n E_n\bigr).
%     \]
% \end{cor}

% \begin{namedthm}[Borel--Cantelli lemma, part I]
%     For $\{E_n\}_n \subseteq \A$, assume $\sum_{n} \mu(E_n) <\infty$, then \[
%         \mu\bigl(\limsup_n E_n\bigr) = 0.
%     \]
% \end{namedthm}

% One can skip the rest of this subsection for now, and come back after reading about the Lebesgue measure on the real line.

% Given $(X,\A,\mu)$, a subset $E\subseteq X$ is called a \df{null set}
% if there is $B\in\mathcal{A}$ such that $E\subseteq B$ and $\mu(B)=0$.
% If $\A$ contains all these null sets, then the measure space is \df{complete}.
% The \df{completion} $\A^\mu$ is the smallest $\sigma$-algebra containing $\A$ such that there exists a measure $\bar{\mu}$, which extends $\mu$ to $\A^\mu$, that makes $(X,\A^\mu)$ complete.

% Why is a complete measure space sometimes desirable? We want to make all subsets of measure zero sets measurable to avoid some technical peculiarity. However, even a complete measure space $(X,\A,\mu)$ may still not measure every subset of $X$.

% The completion of a measure space is given explicitly, as stated in the following theorem.

% \begin{thm}[{\cite[Theorem 1.9]{folland1999}}]
%     The completion $\A^\mu$ is unique, which is given by \[
%         \A^\mu =\{E\cup F:E\in\A\text{ and }F\subseteq N\text{, where }N\text{ is a null set}\}.
%     \]
%     In addition, the measure $\bar{\mu}$ given by $\bar{\mu}(E\cup F)=\mu(E)$ not only completes $\A$, but also is the unique extension of $\mu$ from $\A$ to $\A^\mu$.
% \end{thm}
% \begin{proof}
%     The first part of the proof is given in the reference. For the uniqueness part, suppose there is some other measure $\hat{\mu}$ on $\A^\mu$ such that $\hat{\mu}(E) = \mu(E)$ for all $E \in \A$. However, there exists some $D \subseteq N$, where $\mu(N) = 0$, such that $\hat{\mu}(E \cup D) \neq \mu(E) = \hat{\mu}(E)$. This implies $\hat{\mu}(D - E) > 0$. Yet $D - E \subseteq N$ where $\hat{\mu}(N) = 0$. This contradicts monotonicity.
% \end{proof}

% To similarly avoid peculiarities caused by null sets, we give the following definitions. The set $A \in \A$ is called an \df{atom} of the measure $\mu$ if the set has positive measure $\mu(A)$, but all its measurable subsets must be either of measure $0$ or of measure $\mu(A)$. A measure is \df{atomless} if there are no atoms.

% \subsection{Two tools from set theory}
% \begin{defn}
% A \df[pi-system@$\pi$-system]{$\pi$-system} on $X$ is a nonempty collection of subsets of $X$ that is closed under finite intersections.

% A \df[lambda-system@$\lambda$-system]{$\lambda$-system} $\mathcal{L}$ on $X$ is a collection of subsets of $X$ such that 
% \begin{enumerate}
%     \item $X\in\mathcal{L}$; 
%     \item \label{enu:prop-diff-lam-sys} if $A,B\in\mathcal{L}$ and $A\subseteq B$, then $B-A\in\mathcal{L}$; (closed under proper differences)
%     \item if $A_{n}\in\mathcal{L}$ and $A_{n}\uparrow A$ then $A\in\mathcal{L}$. (closed under ascending countable unions)
% \end{enumerate}
% \end{defn}
% \begin{defn}
%     A \emph{monotone class} on $X$ is a collection of subsets of $X$ that is closed under ascending countable unions and descending countable intersections.
    
% \end{defn}
% \begin{namedthm}[Dynkin's $\pi$-$\lambda$ theorem] \label{thm:pi-lambda}
%      Within $X$, if $\mathcal{K}$ is a $\pi$-system that is contained in a $\lambda$-system $\mathcal{L}$, then $\sigma(\mathcal{K})\subseteq\mathcal{L}$.
% \end{namedthm}
% \begin{namedthm}[Monotone class theorem] \label{thm:monotone-class}
%      Given an algebra $\A_0$ of sets, then the monotone class $\mathcal{M}$ generated by $\A_0$ coincides with the $\sigma$-algebra $\sigma(\A_0)$ generated by $\A_0$.
% \end{namedthm}

% We do not prove these results in this note; they are very complicated and not very interesting in the end. ``The generated is the smallest'' is the main idea behind these proofs though. The proof of the next result should provide the readers with a general idea what proofs of this sort look like.

% This next result is of theoretical significance. It tells us a $\pi$-system that generates the $\sigma$-measure identifies the measure.

% \begin{namedthm}[Coincidence criterion {\cite[Proposition~1.15]{Ambrosio_2011}}]
%     Let $\mu_1$ and $\mu_2$ be two measures on $(X,\A)$. Suppose we can find a $\pi$-system $\mathcal{K}$ on which the two measures agree, and $\sigma(\mathcal{K}) = \A$.

%     If $\mu_1(X) = \mu_2(X) < \infty$ (for example, both are probability measures), then the two measures agree on the entire $\A$.

%     More generally, if there exists $\{X_n\} \subseteq \mathcal{K}$ such that $X_n \uparrow X$ and \[
%         \mu_1(X_n) = \mu_2(X_n) <\infty \text{ for all }n\in \N,
%     \] then the two measures agree on the entire $\A$.
% \end{namedthm}
% \begin{proof}
%     Assume $\mu_1(X) = \mu_2(X) < \infty$. Define $\mathcal{D}$ to be the collection of all sets in $\A$ on which the two measures agree. It is easy to verify that $\mathcal{D}$ becomes a $\lambda$-system. Now invoke \nameref{thm:pi-lambda} and conclude that $\mathcal{D} = \mathcal{A}$. Without the finiteness assumption, we cannot verify condition~\ref{enu:prop-diff-lam-sys} for a $\lambda$-system  that makes $\mu(B) - \mu(A)$ computable.

%     Now consider the general assumption. We define for each $n$ \begin{align*}
%         \A_n & = \{E \cap X_n : E \in \A\}\text{, which is a $\sigma$-algebra, and} \\
%         \mathcal{K}_n & = \{E \cap X_n : E \in \mathcal{K}\}\text{, which is a $\pi$-system contained in $\A_n$.}
%     \end{align*}
%     Then $\mu_1$ and $\mu_2$ restricted to $(X_n,\A_n)$ is a finite measure. By the special case above, the two measures coincide on $\sigma(\mathcal{K}_n)$.

%     Now we prove $\A_n \subseteq \sigma(\mathcal{K}_n)$. Check that since $X_n \in \mathcal{K}$, \[
%         \{E \subseteq X : E \cap X_n \in \sigma(\mathcal{K}_n)\}
%     \] is a $\sigma$-algebra containing $\mathcal{K}$, and hence $\A$.

%     Now for each $n$ and all $E \in \mathcal{A}$, the two measures agree on $E \cap X_n$. Now take $n \to \infty$ and we see that $\mu_1 = \mu_2$.
% \end{proof}

% \subsection{Extension theorems}
% \begin{defn}
%     The \df{outer measure} on $X$ is a function $\mu^{*}\colon\wp(X)\to[0,\infty]$ such that 
%     \begin{enumerate}
%     \item $\mu^{*}(\emptyset)=0$; (emptyset)
%     \item if $A\subseteq B$, then $\mu^{*}(A)\leq\mu^{*}(B)$; (monotonicity)
%     \item For subsets $A_{1},A_{2},\dotsc$ of $X$, $\mu^{*}(\cup_{i=1}^{\infty}A_{i})\leq\sum_{i=1}^{\infty}\mu^{*}(A_{i})$. ($\sigma$-subadditivity)
%     \end{enumerate}
%     A \df[outer null set]{null set} with respect to the outer measure $\mu^{*}$ is just a set with $\mu^{*}$-value 0.
% \end{defn}

% Let $\mathcal{C}$ be a collection of subsets of $X$ such that $\emptyset\in\mathcal{C}$ and there are $D_{1},D_{2},\dotsc$ in $\mathcal{C}$ such that $\cup_{i\in\N}D_{i}=X$. Suppose $\ell\colon\mathcal{C}\to[0,\infty]$ with $\ell(\emptyset)=0$. Now if we define for all $E\in \wp(X)$ 
% \[
%     \mu^{*}(E)=\inf\biggl\{\sum_{i=1}^{\infty}\ell(A_{i}):E\subseteq\bigcup_{i=1}^{\infty}A_{i}\text{, where every }A_{i}\in\mathcal{C}\biggr\},
% \]
% then $\mu^{*}$ is an outer measure on $X$. (Note that by assumption
% the infimum is taken over a nonempty set, and hence always exists. For simplicity one may just assume $X \in \mathcal{C}$ as well.)
% The proof is routine.

% Here are some forewords to what we will construct.
% \begin{itemize}
% \item Let $X=\R$, $\mathcal{C}$ be the collection of all left-open right-closed
% intervals, and $\ell\bigl((a,b]\bigr)=b-a$. This gives the Lebesgue
% outer measure $m^{*}$ used to construct the Lebesgue measure $m$.
% \item Let $f\colon\R\to\R$ be an increasing right-continuous\footnote{We will use ``increasing'' and ``strictly increasing'' in our note. Right-continuity at $x$ means continuity from $x^{+}$.}
% function. we let $\ell\bigl((a,b]\bigr)=f(b)-f(a)$. The $\mu^{*}$
% that arises from this is used to construct the Lebesgue--Stieltjes measure.
% \end{itemize}

% \begin{defn}
%     For an outer measure $\mu^{*}$, a set $A\subseteq X$ is \df[outer measurable]{$\mu^{*}$-measurable} if for all $E\subseteq X$, \[
%         \mu^{*}(E)=\mu^{*}(E\cap A)+\mu^{*}(E\cap A^\cpl).
%     \] 
% \end{defn}

%     This characterizes a collection of sets that are well-behaved under set operations, which leads to the next theorem. Note it $A$ is $\mu^{*}$-measurable if and only if for all $E$ with $\mu^{*}(E)<\infty$, \[
%         \mu^{*}(E)\geq\mu^{*}(E\cap A)+\mu^{*}(E\cap A^\cpl).\]
% \begin{namedthm}[Carathéodory's theorem]
%     Given an outer measure $\mu^{*}$ on $X$, then the collection of $\A$ of $\mu^{*}$-measurable sets is in fact a $\sigma$-algebra on $X$. Let $\mu=\mu^{*}|_{\mathcal{A}}$, then $\mu$ is a measure. Also the $\sigma$-algebra $\A$ contains all the null sets, i.e., $(X,\A,\mu)$ is complete.
% \end{namedthm}

% \begin{proof}
% $\A$ is clearly closed under complements. We then check $\A$ is an algebra (the union of two sets in $\A$ is still in $\A$), and show $\mu^{*}$ is finitely additive on $\A$.

% We wish to extend finite additivity to countable additivity. We let
% $B_{n}=\cup_{j=1}^{n}A_{j}$ and $B=\cup_{j=1}^{\infty}A_{j}$. For
% any $E$, we may conclude that 
% \[
% \mu^{*}(E\cap B_{n})=\sum_{j=1}^{n}\mu(E\cap A_{j}).
% \]
% It follows that $\mu^{*}(E)\geq\sum_{j=1}^{n}\mu^{*}(E\cap A_{j})+\mu(E\cap B^{\mathrm{c}}).$
% Take $n\to\infty$ we may conclude 
% \begin{align*}
% \mu^{*}(E) & \geq\sum_{j=1}^{\infty}\mu^{*}(E\cap A_{j})+\mu^{*}(E\cap B^{\mathrm{c}})\\
%  & \geq\mu^{*}\Bigl(\bigcup_{j=1}^{\infty}(E\cap A_{j})\Bigr)+\mu^{*}(E\cap B^{\mathrm{c}})\\
%  & =\mu^{*}(E\cap B)+\mu^{*}(E\cap B^{\mathrm{c}})\geq\mu^{*}(E).
% \end{align*}
% It follows that $B\in\A$, and if we let $E=B$, the first inequality
% (which is an equality) gives countable additivity.

% It is easy to show $\A$ contains all $\mu^{*}$-null sets: for $N$
% such that $\mu^{*}(N)=0$, for any $E$ we have 
% \[
% \mu^{*}(E)\leq\mu^{*}(E\cap N)+\mu^{*}(E\cap N^{\mathrm{c}})\leq\mu^{*}(E\cap N^{\mathrm{c}})\leq\mu(E).\qedhere
% \]
% \end{proof}

% \begin{namedthm}[Carathéodory's extension theorem]
%     For algebra $\A_{0}$ on $X$ and its premeasure
% $\mu_{0}$, let 
% \[
% \mu^{*}(E)=\inf\biggl\{\sum_{i=1}^{\infty}\mu_{0}(A_{i}):E\subseteq\bigcup_{i=1}^{\infty}A_{i}\text{, where every }A_{i}\in\A_{0}\biggr\}
% \]
% for all $E\subseteq X$. Then (1) $\mu^{*}$ is an outer measure on $X$, and hence by Carathéodory's theorem it gives a meausure space
% $(X,\sigma(\A_{0}),\mu)$; (2) $\mu^{*}|_{\A_{0}}=\mu_{0}$; (3) every
% set in $\A_{0}$ is $\mu^{*}$-measurable; (4) if $\mu_{0}$ is $\sigma$-finite,
% then $\mu$ in (1) is the unique extension of $\mu_{0}$ from $\A_{0}$
% to $\sigma(\A_{0})$.
% \end{namedthm}

% \begin{proof}
% When proving $\mu^{*}(E)\geq\mu_{0}(E)$ in (2), consider the disjoint
% sets $B_{n}=E\cap(A_{n}-\cup_{i=1}^{n-1}A_{i})$. Then $\cup_{n=1}^{\infty}B_{n}=E$,
% which implies $\sum_{n=1}^{\infty}\mu_{0}(A_{n})\geq\sum_{n=1}^{\infty}\mu_{0}(B_{n})=\mu_{0}(E)$.
% Then take infimum. (3) is fairly straightforward from definition.

% To prove (4), let measure $\nu$ be another extension. Consider $E\in\sigma(\A_{0})$
% and $\{A_{i}\}_{i=1}^{\infty}\subseteq\A_{0}$ that covers $E$, we
% have 
% \[
% \nu(E)\leq\sum_{i=1}^{\infty}\nu(A_{i})=\sum_{i=1}^{\infty}\mu_{0}(A_{i}).
% \]
% Take infimum and we get $\nu(E)\leq\mu(E)$.

% Now let $A=\cup_{i=1}^{\infty}A_{i}$, then 
% \[
% \mu(A)=\lim_{n\to\infty}\mu(\cup_{i=1}^{n}A_{i})=\lim_{n\to\infty}\nu(\cup_{i=1}^{n}A_{i})=\nu(A).
% \]
% If $\mu(E)<\infty$, then for any $\epsilon>0$ we may choose $\{A_{i}\}_{i=1}^{\infty}$
% such that $\mu(A-E)<\epsilon$. It follows that 
% \[
% \mu(E)\leq\mu(A)=\nu(A)=\nu(E)+\nu(A-E)<\nu(E)+\epsilon.
% \]
%  Therefore $\mu(E)=\nu(E)$.

% Now suppose we have $X=\cup_{j=1}^{\infty}B_{j}$ such that $\mu_{0}(B_{j})<\infty$
% and that the $B_{j}$'s are pairwise disjoint. Then for $E\in\sigma(\A_{0})$,
% we have 
% \[
% \mu(E)=\sum_{j=1}^{\infty}\mu(E\cap B_{j})=\sum_{j=1}^{\infty}\nu(E\cap B_{j})=\nu(E),
% \]
% where the second equality follows from what we have previously.
% \end{proof}

% \subsection{Lebesgue measure}
% \begin{fact}
%     If we assume the Axiom of Choice, then we can use Zorn's lemma to prove $\mathcal{L} \neq \wp(X)$.
% \end{fact}

% \begin{thm}
%     Lebesgue--Stieltjes measures can be approximated inside by compact sets (in particular, closed sets) and outside by open sets.
% \end{thm}

% \begin{thm}
%     For a finite measure $\mu$ on a metric space $X$ with the Borel $\sigma$-algebra, $\mu$ can be approximated inside by closed sets and outside by open sets.
% \end{thm}

% Bill Theorem 12.3


% This theorem is of particular importance in probability theory.

% \begin{thm}[{\cite[Theorem~1.16]{folland1999}}] \label{thm:increasing-rcont-Borel-measure-connection} \leavevmode
%     \begin{enumerate}
%         \item \label{enu:CDF-measure} Let $F\colon \R \to \R$ be an increasing, right-continuous function, then there is a unique associated Borel measure $\mu_F$ on $\R$ such that \[
%         \mu_F(a,b] = F(b) - F(a)\quad \text{for all }a,b\in \R.
%     \] If $G$ is another increasing, right-continuous function, then $\mu_F = \mu_G$ if and only if $F$ and $G$ differ by a constant.
%         \item \label{enu:measure-CDF} Conversely, if $\mu$ is a finite Borel measure on $\R$, then the function $F\colon \R \to \R$ given by $F(x) = \mu(-\infty,x]$ is increasing and right-continuous. Furthermore $\mu = \mu_F$, and the function has left limit, i.e., $\lim_{y \to x^-} F(y)$ exists at every $x \in \R$. More specifically, \begin{equation} \label{eq:CDF-left-limits}
%              \lim_{y \to x^-} F(y) = \mu(-\infty,x).
%         \end{equation}
%     \end{enumerate}
% \end{thm}

% Regarding equation \eqref{eq:CDF-left-limits}, it is customary to write $F(x-) = \lim_{y \to x^-} F(y)$ when the limit exists. Note that having left limits implies \[\mu(\{x\}) = F(x) - F(x-)\] for all $x \in \R$.

% \begin{proof}
%     Caratheodory, pi-lambda
% \end{proof}

%     For part~\ref{enu:measure-CDF}, more generally, if $\mu$ is a Borel measure on $\R$ that is finite on all bounded Borel sets, then $F$ can be instead defined by \[
%         F(x) = \begin{cases*}
%             \mu (0,x] & if $x > 0$, \\
%             0 & if $x = 0$, \\
%             -\mu(x,0] & if $x < 0$,
%         \end{cases*}
%     \] and the same conclusions still hold.

% \section{Measurable functions and integration}
% \subsection{Measurable functions}\label{sec:measurable-functions}

% \begin{defn}
%     Given two measurable spaces $(X,\mathcal{M})$ and $(Y,\mathcal{N})$, a function $f\colon X \to Y$ is called a \df{measurable function} if $f^{-1}(A) \in \M$ for all $A \in \mathcal{N}$.
    
%     We would stress that the function is $\M/\mathcal{N}$-measurable if the context is not clear. When $(Y,\mathcal{N}) = (\R,\B)$, we usually say $f$ is $\M$-measurable\footnote{Now be aware that either a set or a function may be called $\M$-measurable.}. Therefore when $\M=\B_X$ or $\mathcal{L}_X$, $f$ would be called Borel or Lebesgue measurable, respectively.
% \end{defn}

% Check on your own that compositions of measurable functions is measurable.

% To check measurability, it suffices to just check preimage condition for a collection of subsets that generates the image $\sigma$-algebra $\mathcal{N}$. This is the content of the next proposition, and is a direct consequence of \cref{prop:induce-s-alg-meas-map}\ref{enu:forward-ind-s-alg}.
% \begin{prop}\label{prop:measurability-generate}
%     If $\mathcal{N}$ is generated by $\mathcal{E}$, then $f\colon X \to Y$ is $\M/\mathcal{N}$-measurable if and only if $f^{-1}(E) \in \M$ for all $E \in \mathcal{E}$.    
% \end{prop}

% With this sufficient condition in mind, it is easy to check that continuous functions between topological spaces are measurable, and increasing/decreasing functions from $\R$ to $\R$ are Borel-measurable.

% Given a set $X$, a measurable space $(Y,\mathcal{N})$, and a function $f\colon X \to Y$, then by \cref{prop:induce-s-alg-meas-map}\ref{enu:forward-ind-s-alg} we know \[
%     \{f^{-1}(A):A\in \mathcal{N}\}
% \] is the smallest $\sigma$-algebra on $X$ that makes $f$ measurable. We call it the \df[sigma-algebra generated by@$\sigma$-algebra generated by!a function]{$\sigma$-algebra generated by $f$}, denoted by $\sigma(f)$.

% More generally, consider a collection of measurable spaces $(Y_\alpha,\mathcal{N}_\alpha)$ over all $\alpha \in I$. Suppose we are given $f_\alpha\colon X \to Y_\alpha$ for all $\alpha$. The \df[sigma-algebra generated by@$\sigma$-algebra generated by functions]{$\sigma$-algebra generated by the class of functions $\{f_\alpha\}_{\alpha \in I}$} on $X$ is defined to be 
% \[
%     \sigma(\{f_\alpha\}_{\alpha\in I}) = \sigma\bigl(\cup_{\alpha \in I} \{f^{-1}(A_\alpha):A_\alpha\in \mathcal{N}_\alpha\}\bigr).
% \] (Recall that union of $\sigma$-algebras is not necessarily a $\sigma$-algebra.)

% \begin{namedthm}[Simple function approximation]
%     Given $f \in L^+(X,\A)$, there exists a sequence of nonnegative simple functions $\{s_n\}_{n=1}^\infty$ such that $s_n \uparrow f$ pointwise. Furthermore $s_n \to f$ uniformly on any set on which $f$ is bounded.
% \end{namedthm}

% Note that the ``furthermore'' part essentially means that every nonnegative bounded measurable function is the increasing uniform limit of nonnegative simple functions.
% \subsection{Nonnegative Lebesgue integrals}

% Repartition function is cadlag


% \begin{namedthm}[Monotone convergence theorem]
%     If $\{f_n\} \subseteq L^+$ such that $f_n \uparrow f$ , then \[
%         \int f = \lim_n \int f_n
%     \]
% \end{namedthm}
% % Note $f_n \uparrow f$ implies $f = \sup_n f_n$ and is thus measurable. Hence $\int f$ makes sense.
% \begin{namedthm}[Fatou's lemma]
%     Let $\{f_n\}\subseteq L^+$, then \[
%         \int \bigl(\liminf_n f_n\bigr) \leq \liminf_n \int f_n
%     \]
% \end{namedthm}

% \subsection{Signed Lebesgue integrals}
% \begin{namedthm}[Lebesgue's dominated convergence theorem]
%     Let $\{f_n\}\subseteq L^1$. If 
%     \begin{enumerate}
%         \item $f_n \to f$ pointwise a.e., [limit]
%         \item and there exists some nonnegative $g \in L^1$ such that $\abs{f_n} \leq g$ a.e.\ for all $n$, [bound]
%     \end{enumerate}
%     then $f \in L^1$ with the $L^1$ convergence \[
%         \lim_n \int \abs{f - f_n} = 0.
%     \] In particular, we have \[
%         \int f = \lim_n \int f_n.
%     \]
    
% \end{namedthm}

% This next result is a special case of the above one.
% \begin{namedthm}[Bounded convergence theorem] \label{thm:bdd-conv-thm}
%     Say $\mu(X) < \infty$. Let $\{f_n\} \subseteq L^1$. If \begin{enumerate}
%         \item $f_n \to f$ pointwise a.e.,
%         \item and there exists some $M \in \R^+$ such that $\abs{f_n} \leq M$ a.e.\ for all $n$, 
%     \end{enumerate}
%     then $f \in L^1$ with the $L^1$ convergence \[
%         \lim_n \int \abs{f - f_n} = 0.
%     \] In particular, we have \[
%         \int f = \lim_n \int f_n.
%     \]
% \end{namedthm}

% \subsection{Connections to the Riemann theory}

% \subsection{Modes of convergence}
% \begin{defn}
%     For a sequence of measurable functions ${f_n}$, we say $f_n$ converges to some function $f$ 
%     \begin{itemize}
%         \item \df[convergence!almost everywhere]{almost everywhere} (a.e.) if \[
%             \mu\{x: \lim_n f_n(x) = f(x)\}^\cpl = 0.
%         \]
%         \item \df[convergence!in L-p@in $L^p$]{in $L^p$} if \[
%             \int \abs{f_n - f}^p \to 0.
%         \]
%         \item \df[convergence!in measure]{in measure} if for any $\epsilon > 0$, \begin{equation} \label{eq:in-measure}
%             \lim_n \mu\{x : \abs{f_n(x) - f(x)} > \epsilon\} = 0.
%         \end{equation}
%     \end{itemize}
%     We say $\{f_n\}$ is 
%     \begin{itemize}
%         \item \df{Cauchy/fundamental in measure} if for any $\epsilon > 0$, there exists $N \in \N$ such that for all $m > n \geq N$, \begin{equation} \label{eq:Cauchy-in-measure}
%             \mu\{x:\abs{f_n(x) - f_m(x)} > \epsilon \} < \epsilon
%         \end{equation}
%     \end{itemize}
%     Note that the ``$>$'' in both \eqref{eq:in-measure} and \eqref{eq:Cauchy-in-measure} can be replaced by ``$\geq$'', obviously.
% \end{defn}

% \begin{thm}[(Properties between different convergences)] \leavevmode
%     \begin{enumerate}
%         \item Limit in the sense of convergence in measure in unique a.e.
%         \item $f_n \to f$ in measure implies $\{f_n\}$ is Cauchy in measure.
%         \item Convergence in $L^p$ implies convergence in measure.
%         \item $f_n \to f$ in measure implies there exists a subsequence $\{f_{n_k}\}$ that converges a.e.\ to $f$ as $k \to \infty$.
%         \item If the measure space is finite, then convergence a.e.\ implies convergence in measure.
%     \end{enumerate}
% \end{thm}

% \begin{exa}
    
% \end{exa}

% \subsection{Littlewood's second and third principles} \label{sec:Littlewood-2nd-3rd}
% \begin{namedthm}[Egoroff's theorem] \label{thm:Egoroff}
%     Say $\mu(X)<\infty$. Let ${f_n}$ be a sequence of $\A$-measurable functions from $X$ to $\R$ (or $\C$). Then for all $\epsilon > 0$, there exists some measurable set $E$ such that \[
%         \mu(E^\cpl) < \epsilon, \quad \text{while } f_n \to f \text{ uniformly on } E.
%     \]
%     We call this conclusion $f_n$ converges to $f$ \df[convergence!almost uniformly]{almost uniformly}.
% \end{namedthm}

% % \begin{xca}[\cite{[}{]}{folland1999}]
% %     If $f_n \to f$ almost uniformly, then $f_n \to f$ a.e.\ and in measure.
% % \end{xca}
% We mention that it is a good exercise to prove \nameref{thm:bdd-conv-thm} using this result.
% \begin{namedthm}[Luzin's theorem]
    
% \end{namedthm}

% \subsection{Uniformly integrable functions}

% Use the material we have discussed so far to prove the following result.
% \begin{xca}[\cite{Royden_2023}] \label{xca:abs-cont-int-motiv}
% Let $f \in L^1(\mu)$. Then
% \begin{enumerate}
%     \item \label{enu:abs-cont-int}for all $\epsilon > 0$, there is a $\delta > 0$ such that \[
%     \mu(E) < \delta \implies \int_E \abs{f} \,d\mu < \epsilon;
% \]
%     \item moreover, for each $\epsilon > 0$, there is some $X_0$ with $\mu(X_0) < \infty$ such that \[
%     \int_{X - X_0} \abs{f} < \epsilon.
% \]
% \end{enumerate}
% \end{xca}

% Notice that \[
%     \biggl\vert\int_E f \,d\mu \biggr\vert \leq \int_E \abs{f} \,d\mu = \biggl\vert\int_{E \cap \{f \geq 0\}} f\,d\mu\biggr\vert + \biggl\vert\int_{E \cap \{f < 0\}} -f \,d\mu\biggr\vert.\]
% Hence conclusion~\ref{enu:abs-cont-int} is equivalent to $\forall\,\epsilon > 0$, $\exists\, \delta > 0$ such that \[
%     \mu(E) < \delta \implies \biggl\vert\int_E f \,d\mu\biggr\vert <\epsilon.
% \]

% This motivates the next definition, which requires \ref{enu:abs-cont-int} to hold uniformly for a class of integrable functions.

% \begin{defn}
%     A set of functions $\F \subseteq L^1(\mu)$ has \df{uniformly absolutely continuous integrals} if for every $\epsilon > 0$, there exists $\delta > 0$ such that \[
%         \mu(E) < \delta \implies \int_E \abs{f} \,d\mu <\epsilon \text{ for all $f \in \F$},
%     \] or equivalently, \[ \biggl\vert\int_E f \,d\mu\biggr\vert <\epsilon \text{ for all $f \in \F$}.
%     \]
% \end{defn}

% The term ``absolutely continuous'' that appear in the definition above is related the notion of an absolutely continuous pair of measures we will discuss in \cref{sec:signed}. Since for $f \in L^1(X,\A,\mu)$, $\nu(E) = \int_E \abs{f} \,d\mu$ defines a finite positive measure $\nu$ on $\A$ that is absolutely continuous with respect to $\mu$. This immediately proves conclusion~\ref{enu:abs-cont-int} in \cref{xca:abs-cont-int-motiv}.

% \begin{defn}
%     A set of functions $\F\subseteq L^1(\mu)$ is \df{uniformly integrable} if \[
%         \lim_{C \to \infty} \sup_{f\in \F} \int_{\{f > C\}} \abs{f}\,d\mu = 0.
%     \]
% \end{defn}

% These two definitions are quite obviously related, as stated by the next proposition.

% \begin{prop}
    
% \end{prop}

% \begin{xca}
%     Suppose there exists some $p > 1$ such that $\sup_{n\in \N} \int \abs{f_n}\,d\mu <\infty$, then the collection $\{f_n\}_n$ is uniformly integrable.
% \end{xca}

% \begin{namedthm}[Vitali's convergence theorem]
%     Suppose $\mu$ is finite. Let $\{f_n\} \subseteq L^1(X,\A,\mu)$, then the following are equivalent: 
%     \begin{enumerate}
%         \item $f \in L^1$ with $f_n \to f$ in $L^1$.
%         \item $f_n \to f$ in measure, and $\{f_n\}$ is uniformly integrable.
%     \end{enumerate}
% \end{namedthm}
% \subsection{Continuity and differentiability of parametrized functions}

% \subsection{Image measures} \label{sec:image-measure}
% Consider a measure space $(X,\mathcal{M},\mu)$ and a measurable space $(Y,\mathcal{N})$. If we have an $(\mathcal{M},\mathcal{N})$-measurable function $\phi\colon X \to Y$, then we can define a function $\mu_{*}\colon \mathcal{N} \to [0,\infty]$ given by \[
%     \mu_{*}(E) =  \mu(\phi^{-1}E)
% \] for all $E\in \mathcal{N}$. This turns out to a measure on $(Y,\mathcal N)$, and we call this the \df{image/pushforward measure} of $\mu$ by $\phi$, denoted by $\mu_*\phi$ or $\mu_{\#}\phi$.

% Image measure characterizes change of variables, which is of basic importance in mathematics. We will use image measures later in \cref{sec:cov,sec:polar,sec:rv-expec}.

% We state the main result below.
% \begin{prop}
%     Under the conditions stated above, let $g\in L^+(Y,\mathcal{N})$ or $g \circ \phi \in L^1(X,\mathcal{M},\mu)$. Then \begin{equation*}
%         \int_X g\bigl(\phi(x)\bigr) \,d\mu(x) = \int_Y g(y) \,d\mu_*(y). %\label{eq:image-m}
%     \end{equation*}
% \end{prop}
% \begin{proof}
%     When $g = \ind_E$ for $E \in \mathcal{N}$, we have \[
%         \text{LHS} = \mu\{x : \phi(x) \in E\} = \mu(\phi^{-1} E) \quad \text{and} \quad 
%         \text{RHS} = \mu_{*}(E).
%     \] Now extend this to simple functions, then nonnegative functions, and then integrable functions.
% \end{proof}

% \section{Product spaces}
% \subsection{Construction of product measures}

% We start with a comparison between product topologies and product $\sigma$-algebras. See \cite[Sections 4.1 and 4.2]{folland1999} for a review bases, subbases and product topologies.

% For topological spaces $(X_\alpha,\mathcal{T}_\alpha)$ ($\alpha \in I$), recall that the \df{product topology} $\mathcal{T}$ on $X = \prod_{\alpha \in I} X_\alpha$ is the topology generated by all coordinate projections $\pi_\alpha\colon X \to X_\alpha$ (i.e., the smallest topology on $X$ that makes all these maps continuous). Explicitly $\mathcal T$ is generated by the collection of subbasic sets \begin{equation} \label{eq:1d-cylinder-top}
%     \{\pi_\alpha^{-1}(U_\alpha): U_\alpha\in \mathcal{T}_\alpha, \alpha \in I\}.
% \end{equation}
    
% For measurable spaces $(X_\alpha, \A_\alpha)$ ($\alpha \in I$), the \df[product sigma-algebra@product $\sigma$-algebra]{product $\sigma$-algebra} $\A = \bigotimes_{\alpha\in I} \A_\alpha$ on $X = \prod_{\alpha \in I} X_\alpha$ is the $\sigma$-algebra generated by all coordinate projections $\pi_\alpha$. Explicitly $\A$ is generated by the collection of sets \begin{equation} \label{eq:1d-cylinder-sa}
%      \{\pi_\alpha^{-1}(E_\alpha): E_\alpha\in \A_\alpha, \alpha \in I\}.
% \end{equation}

% Define the general \df{cylinder sets}\footnote{This definition similarly holds for other set-collection pairs.} on the product of topological spaces $(X_\alpha,\mathcal{T}_\alpha)$ and measurable spaces $(X_\alpha,\A_\alpha)$ to be the sets of form \[
%     \bigcap_{j=1}^n \pi_{\alpha_{j}}^{-1}(U_{\alpha_j}) \quad \text{and} \quad \bigcap_{j=1}^n \pi_{\alpha_{j}}^{-1}(E_{\alpha_j}),
% \] for any $n \in \N$, respectively. To put them into simple words, they are finite intersections of preimages of the projections. These general cylinder sets on the product of topological spaces, as finite\footnote{As another reminder, if the intersection is allowed to be arbitrary, then we get a larger topology called the \df{box topology}. The box topology is generated by full-dimension products of open sets. When the product is finite, the box topology and the product topology coincide.} intersections of subbasic sets in \eqref{eq:1d-cylinder-top}, form a basis for the product topology $\mathcal{T}$.

% The collection of sets in \eqref{eq:1d-cylinder-top} and \eqref{eq:1d-cylinder-sa} are $1$-dimensional cylinders. It is a well-known fact that $\sigma$-algebras, unlike topologies, cannot be written out explicitly from the elementary sets they are generated from. Therefore in studying product $\sigma$-algebras, we should work primarily with $1$-dimensional cylinder sets of the form \[
%     E_\beta \times \prod_{\alpha \neq \beta} X_\alpha
% \] over all $\beta \in I$ and $E_\beta \in \A_\beta$.

% In fact we can work with even simpler cylinder sets. The next result is something you should expect. Yet the proof is a little weird, like most arguments involving algebras of sets.

% \begin{prop} \label{prop:prod-s-algebra-generate}
%     Suppose each $\A_\alpha$ is generated by $\mathcal{E}_\alpha$. Then $\bigotimes_{\alpha} \A_\alpha$ is generated by the collection \[
%         \mathcal{K} = \{\pi_\alpha^{-1} (E_\alpha) : E_\alpha \in \mathcal{E}_\alpha, \alpha \in I\}.
%     \]
% \end{prop}
% \begin{proof}
%     Let the collection in \eqref{eq:1d-cylinder-sa} be $\mathcal{J}$. Clearly $\mathcal{K} \subseteq \mathcal{J}$. To see the other inclusion, consider the induced $\sigma$-algebra on $X_\alpha$ \[
%         \{E \subseteq X_\alpha : \pi_\alpha^{-1}(E) \in \sigma(\mathcal{K})\},
%     \] which contains $\mathcal{E}_\alpha$ and hence $\A_\alpha$. This means $\pi_\alpha^{-1}(E) \in \sigma(\mathcal{K})$ for all $\alpha \in I$ and $E \in \A_\alpha$. Hence $\mathcal{J} \subseteq \sigma(\mathcal{K})$. The proof is now complete.
% \end{proof}

% We have introduced very general definitions above, but in practice we only deal with cases where the index set $I$ is countable. The reader should verify on their own that when $I$ is countable, $\A = \bigotimes_{n=1}^\infty \A_n$ is generated by \[
%     \biggl\{\prod_{n=1}^\infty E_n :E_n \in \A_n \biggr\}.
% \]

% Since the Borel $\sigma$-algebra is the $\sigma$-algebra generated by open set, while the topological space consists of all the open sets. With our above detailed comparisons between product $\sigma$-algebras and product topological spaces, the Borel $\sigma$-algebra from the product topology and the product Borel $\sigma$-algebra from individual spaces should be the same, under some conditions.

% \begin{thm}
%     For any separable metric spaces $X_1,X_2,\dotsc$ (finite or countably infinite), we have \begin{equation} \label{eq:borel-prod-agreement}
%         \B(X) = \B(X_1) \otimes \B(X_2) \otimes \dotsb,
%     \end{equation} where $X = X_1 \times X_2 \times \dotsb$ with product topology $\mathcal{T}$ given by the supremum metric.
% \end{thm}
% \begin{proof}
%     We follow the proof in \cite{Kallenberg_2002}\footnote{This is the second edition of the book. The new proof in the third edition is very misleading, and I suspect there are many errors in the new edition.}.
    
%     Let $\mathcal{J}$ be the class of $1$-dimensional cylinder sets \[
%         X_1\times \dotsb \times X_{k-1} \times U_k \times X_{k+1} \times \dotsb
%     \] over all $k \in \N$ and $U_k \in \mathcal{T}_k$.
    
%     Since $\mathcal{J}$ consists entirely of open sets, and $\text{RHS} = \sigma(\mathcal{J})$ by \cref{prop:prod-s-algebra-generate}, we have $\text{LHS} \supseteq \text{RHS}$. \emph{Note that this inclusion does not use any topological assumptions on the $X_n$'s.}
    
%     If we can now show that $\mathcal{T} \subseteq \sigma(\mathcal{J})$, the proof will be complete. Now $(X,\mathcal{T})$, as a product of separable metric spaces, is still a separable metric space. Here we cite a result from \cite{Bogachev_2020}.
    
%     \begin{center}
%     \noindent\begin{minipage}[t]{0.9\columnwidth}
%         \begin{thm*}[{\cite[Theorem 1.2.13]{Bogachev_2020}}]
%         Every collection of open sets in a separable metric space contains an at most countable subcollection with the same union.
%         \end{thm*}
%     \end{minipage}
%     \end{center}
    
%     Therefore every open set in $X$ is a countable union of basic open sets. Since a topological basis is given by finite intersections of the cylinder sets in $\mathcal{J}$, we then have $\mathcal{T} \subseteq \sigma(\mathcal{J})$.
%     % For the countable dense subset $D_k$ of $X_k$, we 
%     % Let $\mathcal{T}$ be the product topology on $X_1 \times X_2 \times \dotsb$.Then \[
%     %     \text{LHS} = \B(\mathcal{T}).
%     % \] Let $\mathcal{C}$ be the collection of $1$-dimensional cylinder sets of the form \[
%     %     X_1 \times \dotsb\times X_{k-1}  \times E_k \times X_{k+1} \times \dotsb,
%     % \] where $E_k \in \mathcal{T}_k$. Then \[
%     %     \text{RHS} = \B(\mathcal{K}).
%     % \]
% \end{proof}

% The direct corollary is that $\B(\R^d) = \bigotimes^d \B(\R^1)$. This theorem overall shows the fundamental importance of Borel $\sigma$-algebra in measure theory and its applications: it connects measurability to the underlying topological spaces.

% As an exercise, use \cref{prop:measurability-generate} to show the following: 
% \begin{xca}[{\cite[Proposition~2.4]{folland1999}}]
%     Given measurable spaces $(X,\M)$ and $(Y_\alpha,\mathcal{N}_\alpha)$ over all $\alpha \in I$. Let $Y = \prod Y_\alpha$ and $\mathcal{N} = \bigotimes \mathcal{N}_\alpha$. Then $f\colon X \to Y$ is $\M/\mathcal{N}$-measurable if and only if each $f_\alpha = \pi_\alpha \circ f$ is $\M/\mathcal{N}_\alpha$-measurable.
% \end{xca}

% \subsection{Integration on product spaces} \label{sec:prod-integrate}
% \begin{namedthm}[Fubini--Tonelli theorem]
    
% \end{namedthm}

% \subsection{Change of variables} \label{sec:cov}
% \subsection{Gamma functions and polar coordinates} \label{sec:polar}
% Let $z \in \C$ with $\Re z > 0$, and we define $f_z\colon (0,\infty)\to \C$ by \[f_z(t) = t^{z-1} e^{-t} = \exp\bigl((z-1)\log t\bigr)\cdot e^{-t}.\] Since 

% $\sigma(S^{n-1})=\frac{2\pi^{n/2}}{\Gamma(n/2)}$ and $m(B^{n})=\frac{1}{n}\sigma(S^{n-1})=\frac{\pi^{n/2}}{\Gamma\bigl(\frac{n}{2}+1\bigr)}$.
% For any $\epsilon>0$, we have $S^{n-1}\subseteq B^{n}(0;1+\epsilon)-B^{n}(0;1)$
% \begin{align*}
% m(S^{n-1}) & \leq m\bigl(B^{n}(0;1+\epsilon)\bigr)-m\bigl(B^{n}(0;1)\bigr)\\
%  & \leq(1+\epsilon)^{n}m(B^{n})-m(B^{n}).
% \end{align*}
% Take $\epsilon\to0^{+}$, it is easy to see that $m(S^{n-1})=0$.
% surface area

% \section{Structure of measures}
% \subsection{Hahn--Jordan decomposition of signed measures} \label{sec:signed}

% \begin{defn}
%     Given a measurable space $(X,\A)$, a \df{signed/real measure} (resp.\ \df{complex measure}) on the space is a function $\mu\colon \A \to \R$ (resp.\ $\mu\colon \A \to \C$) such that \begin{enumerate}
%         \item $\mu(\emptyset) = 0$; 
%         \item \label{enu:abs-conv-cond-signed} $\mu(E) = \sum_{n=1}^\infty \mu(E_n)$ for all measurable partitions $\{E_n\}$ of $E$.
%     \end{enumerate}
% \end{defn}

% Note condition~\ref{enu:abs-conv-cond-signed} implicitly requires the series $\sum \mu(E_n)$ to be absolutely convergent. An important result that says a series is absolutely convergent if and only if any rearrangement of terms in a series yields the same limiting sum; see \cite[Theorems~3.54 and 3.55]{Rudin_principles_1976}.

% Many textbooks define the codomain of a signed measure to include one of $+\infty$ or $-\infty$. We do not adopt this convention because it is hardly used in applications, and many complications are avoided. Furthermore, restricting the codomain to the reals allows us to discuss signed and complex measures simultaneously. We will state our proofs for signed measures. To distinguish signed/complex measures from the measures we have been discussing previously, we call measures that take nonnegative values \df[positive measure]{positive measures}.

% Continuity from above and below still holds for signed and complex measures. The proof here is the same as the one for positive measures.
% \begin{xca}
%     Let $\mu$ be a signed/complex measure. If $E_n \uparrow E$ or $E_n \downarrow E$ in $\A$, then $\mu(E) = \lim_n(E_n)$.
% \end{xca}
% However monotonicity no longer holds for signed/complex measures, but we may make the following definitions for a signed measure.

% \begin{defn}
%     For a signed measure $\mu$, a measurable set $A$ is a \df[positive/negative/null set for a signed measure]{positive (negative, or null) set} if for every measurable subset $B$ of $A$, $\mu(B)\geq0$ ($\leq 0$, or $=0$). Equivalently, the measurable set $A$ is positive (negative, or null) if for all $E\in \A$, $\mu(E\cap A) \geq 0$ ($\leq 0$, or $= 0$).
% \end{defn}

% \begin{namedthm}[Hahn decomposition]
%     Let $\mu$ be a signed measure on $(X,\A)$. Then $X$ has a partition into $P$ and $N$ such that $P$ is a positive set and $N$ is a negative set.

%     Furthermore, if $P'$ and $N'$ is another such partition, then $P \triangle P' = N \triangle N'$ is null. This means that the Hahn decomposition is \emph{essentially unique}.
% \end{namedthm}
% \begin{proof}
%     First we show the essential uniqueness. Consider a measurable set $E_1 \subseteq P - P'$. This $E_1$, as a subset of $P$, must have measure $\geq 0$. Yet at the same time $E_1 \subseteq N' - N\subseteq N'$, which implies that $\mu(E_1)\leq 0$. Therefore $\mu(E_1) = 0$. By the same reasoning with $P'$ switching $P$ and $N$ switching $N'$, we should have $\mu(E_2) = 0$ for all measurable subsets $E_2$ of $P'-P$. Since $P\triangle P' = N \triangle N' = (P - P')\cup(P' - P)$, it is clear that this is a null set with respect to the signed measure $\mu$.

%     Now we prove the existence. We follow the presentation in \cite{Falkner_2019}, which avoids the axiom of dependent choice used in the proofs of most textbook authors.

%     To show the existence of the partition $X = P \cup N$, it suffices\footnote{This is also a necessary condition.} to find some measurable $N$ such that for all $E \in \A$, $\mu(E)\geq \mu(N)$. Now we prove this claim. By assumption we have $\mu(N)\leq \mu(\emptyset) = 0$. Now for any $A \in \A$, we have \[
%         \mu(N) + \mu(N\cap A) \leq \mu(N-A) + \mu(N\cap A) = \mu(N).
%     \] Therefore $N$ is a negative set. For any $A \in \A$, we also have $P\cap A = A - N$ and \[
%         \mu(N) \leq \mu(A) = \mu(A - N) + \mu(N).
%     \] Therefore $\mu(P\cap A)\geq 0$, which means $P$ is a positive set.
    
%     Now we find such an $N$ with the smallest measure over all measurable sets. Let $L = \inf\{\mu(A): A\in \A\}$, then we need to find $N \in \A$ such that $L = \mu(N)$. Since $\A \neq \emptyset$, by countable choice we can take a sequence $\{D_n\}\subseteq \A$ with $\mu(D_n)\to L$.

%     Let $\A_n$ be the algebra of subsets of $\cup_{n=1}^\infty D_n$ generated by $\{D_k\}_{k=1}^n$, which is a finite collection\footnote{As an exercise, show that the $\sigma$-algebra generated by a collection of $n$ sets can have at most $2^{2^n}$ sets.}. Therefore $\mu_n \coloneqq \mu|_{\A_n}$ achieves its minimum on the collection $\A_n$, say at $E_n$. Note the same argument that proved the sufficient condition for finding a Hahn decomposition clearly works for the premeasure $\mu|_{\A_n}$ on the algebra $\A_n$: we have $E_n$ is a $\mu_n$-negative set and $E_n^\cpl$ is a $\mu_n$-positive set on $\A_n$.

%     We claim that the desired $N = \liminf_m E_m$. First let $A_m^n=\cap_{k=m}^n E_m$ and let $A_m = \cap_{k\geq m}E_m$. Then  \[\mu(A_m^n)\to \mu(A_m)\] as $n\to \infty$. Furthermore the limit above is a decreasing one: note \begin{align*}
%         \mu(A_m^{n-1}) & = \mu(A_m^n) + \mu(A_m^{n-1} - E_k) \\
%         & = \mu(A_m^n) + \mu(A_m^{n-1}\cap E_n^\cpl) \\
%         & \geq \mu(A_m^n), 
%     \end{align*}
%     where the last inequality follows from the observation that $E_n^\cpl$ is $\mu_n$-positive set on $\A_n$ and $A_m^{n-1} \in \A_n$.

%     Now by our choice of $E_m$, we have \[
%         \mu(D_m) \geq \mu(E_m) = \mu(A_m^m)\geq \mu(A_m^{m+1}) \geq \dotsb.
%     \] Therefore \[\mu(D_m) \geq \mu(A_m) \geq L,\] and taking $m \to \infty$ gives us $\mu(A_m) \to L$ as $m\to \infty$. Now the magic takes place. We know $A_m \uparrow \liminf_m E_m$, and thus $\mu(\liminf E_m) = \lim \mu(A_m)$. The two limits must agree, and hence $L = \mu(\liminf E_m)$. This finishes the proof. 
% \end{proof}

% signed/complex measures are bounded.

% \begin{defn}
%     Let $\mu$ and $\nu$ be two positive/signed/complex measures on $(X, \A)$. We say $\mu$ and $\nu$ are \df{mutually singular}, denoted by $\mu \perp \nu$, if $X$ can be partitioned into two measurable subsets $A$ and $B$, such that \[
%         \mu(B) = 0 \quad \text{and} \quad \nu(A) = 0,
%     \] or equivalently, for all $E\in \A$, \[
%         \mu(E) = \mu(E\cap A) \quad \text{and} \quad \nu(E) = \nu(E \cap B).
%     \]
% \end{defn}

% \begin{namedthm}[Jordan decomposition]
%     Let $\mu$ be a signed measure on $(X,\A)$. Then there exist unique two finite positive measures $\mu^+$ and $\mu^-$ on $(X,\A)$ such that \[
%         \mu = \mu^+ - \mu^- \quad \text{and} \quad \mu^+ \perp \mu^-.
%     \]
% \end{namedthm}
% \begin{defn} \label{def:abs-cont}
%      Let $\mu$ be a positive measure and $\nu$ be a positive/signed/complex measure on $(X, \A)$. We say $\nu$ is \df[absolutely continuous measures]{absolutely continuous} with respect to $\mu$, denoted by $\nu \ll \mu$, if for all $E\in \A$, \begin{equation} \label{eq:def-abs-cont}
%          \mu(E) = 0 \implies \nu(E) = 0.
%      \end{equation}
        
%     More generally, to define absolute continuity $\nu \ll \mu$ for signed/complex $\mu$, we change \eqref{eq:def-abs-cont} to \begin{equation} \label{eq:def-abs-cont-sign-cplx}
%         \abs{\mu}(E) = 0 \implies \nu(E) = 0.
%     \end{equation} This is a definition not used much in practice.
% \end{defn}
% One should check that $\nu \ll \mu$ if and only if $\abs{\nu} \ll \mu$ if and only if $\nu^+ \ll \mu$ and $\nu^- \ll \mu$. Also check that $\nu$ and $\nu$ are \df{equivalent measures}, in the sense that \[
%     \nu \ll \abs{\nu} \ll \nu.
% \]


% \subsection{Radon--Nikodym theorem and Lebesgue decomposition}
% Depending on what kind of measures we are looking at, there exists multiple versions of the Radon--Nikodym theorem. The following version is the most basic one in practice. It considers a pair of $\sigma$-finite and finite measures.
% \begin{namedthm}[Radon--Nikodym theorem] \label{thm:Radon-Nikodym}
%     Let $\mu$ be a $\sigma$-finite measure and $\nu$ be a finite measure on $(X,\A)$, where $\nu \ll \mu$. Then there exists an $\A$-measurable function $f$ such that \[
%         \nu(E) = \int_E f \,d\mu \quad \text{for all }E\in \mathcal{A}.
%     \]
%     Furthermore this $f$ is nonnegative and unique in $L^1(X,\A,\mu)$.

%     If the $\nu$ above is given as a signed/complex measure instead, then the same conclusions still hold after dropping $f$ is nonnegative. If $\nu$ is given as a $\sigma$-finite measure instead, the function $f$ becomes nonnegative real-valued\footnote{i.e., $f$ takes values in $[0,\infty)$.}, and is unique a.e.
% \end{namedthm}
% Our $f$ here is called the \df{density/Radon--Nikodym derivative} of $\nu$ with respect to $\mu$, denoted by $d\nu/d\mu$.

% We summarize two standard proofs of this theorem. The first of which uses results from Hilbert spaces, while the second one is based on variational principles.
% \begin{proof}[Proof 1, using Hilbert spaces]
    
% \end{proof}
% \begin{proof}[Proof 2, using variational principles]
    
% \end{proof}

% \begin{namedthm}[Lebesgue decomposition]\label{thm:Leb-decomp}
%      Let $\mu$ be a positive measure and $\nu$ be a signed/complex measure on $(X,\A)$. Then 
%      \begin{enumerate}
%          \item \label{enu:decomp} there exist two unique signed/complex measures $\nu_a$ and $\nu_s$ on $(X,\mathcal{A})$ such that \[
%             \nu = \nu_{a} + \nu_{s}\text{, where }\nu_a \ll \mu \text{ and } \nu_s \perp \mu;
%          \]
%          \item \label{enu:derivative} % there exists an $\A$-measurable function $f$, nonnegative and unique in $L^1(X,\A,\mu)$, such that \[\nu_a(E) = \int_E f \,d\mu \quad \text{for all }E\in \mathcal{A}.\]
%      \end{enumerate}
% \end{namedthm}

% We briefly discuss Lebesgue decomposition for other types of measures below.
% \begin{itemize}
%     \item If $\nu$ is given as a positive/finite/$\sigma$-finite measure instead, then ``positive'' becomes ``positive''/``finite''/``$\sigma$-finite'' in conclusion~\ref{enu:decomp}.
%     \item If $\nu$ is given as a $\sigma$-finite measure instead, then in conclusion~\ref{enu:decomp} $\nu_a$ and $\nu_s$ become $\sigma$-finite.
%     \item Conclusion~\ref{enu:decomp} continues to hold if $\mu$ and $\nu$ are both signed or complex. Recall the definition of absolute continuity in this case from \eqref{eq:def-abs-cont-sign-cplx}.
%     \item The theorems can be generalized to the case when $\mu$ has no assumption while $\nu$ is an \df[s-finite measure@$s$-finite measure]{$s$-finite measure}, which is a sum of countably many finite measures. See \cite{Falkner_2019}.
% \end{itemize}
% \begin{rem}
%     % This paragraph is borrowed from \cite[Section 3.2]{Bogachev_2007}.
    
%     % Given a $\sigma$-finite positive measure $\mu$ on $(X,\A)$, then every finite nonnegative measurable function (not necessarily integrable) defines the $\sigma$-finite positive measure $d\nu_{a} = f d\mu.$ Since $X$ can be written as $\cup_{n=1}^\infty X_n$, where each $X_n$ is $\mu$-finite. 
%     If $\nu$ is given as a signed measure instead, then write $\nu = \nu^+ - \nu^-$, and then use the above version of \nameref{thm:Leb-decomp} to write
    
%     For each $n\in \N$, set $\nu_n (E) = \nu(E\cap X_n)$ for all $E\in \A$ and get a finite measure $\nu_n$. Now apply \nameref{thm:Leb-decomp} for finite $\nu$ above
% \end{rem}
% \subsection{Differentiation}
% \subsection{Functions of bounded variations}
% \subsection{Absolutely continuous functions}
% \begin{defn}
%     Let $I \subseteq \R$ be an interval. A function $f\colon I\to \R$ is absolutely continuous if for all $\epsilon > 0$, there exists $\delta > 0$ such that \[
%         \sum_{i=1}^n (b_i - a_i) < \delta \implies \sum_{i=1}^n \abs{f(b_i) - f(a_I)} <\epsilon
%     \] holds for any finite family of pairwise disjoint open intervals $\{(a_i,b_i)\}_{i=1}^n$ contained in $I$.
% \end{defn}
% \subsection{Fundamental theorem of calculus}
% \begin{namedthm}[Fundamental theorem of calculus (for Lebesgue integrals)]
%     For $f\colon [a,b]\to \R$, the following are equivalent: 
%     \begin{enumerate}
%         \item $f$ is absolutely continuous; 
%         \item there exists a Lebesgue integrable function $g$ on $[a,b]$ such that \[
%             f(x) = f(a) + \int_a^x g(t)\,dt
%         \] for all $x \in [a,b]$.
%         \item $f$ has derivative $f'$ almost everywhere, and $f'$ is Lebesgue integrable with \[
%             f(x) = f(a) + \int_{a}^x f'(t)\,dt
%         \] for all $x \in [a,b]$.
%     \end{enumerate}
% \end{namedthm}

% Bogachev 5.4.5 4.7.60

% \section{Lebesgue spaces}
% \subsection{When \texorpdfstring{$1 \leq p < \infty$}{1 <= p < infinity}}

% \subsection{When \texorpdfstring{$p = \infty$}{p = infty}}

% \subsection{The Hilbert space \texorpdfstring{$L^2$}{L2}}

% \subsection{Dual spaces}

% \newpage
% \phantomsection
% \addcontentsline{toc}{part}{Interlude}
% \part*{\Large Interlude: Between Measure and Probability}

% \newpage

% \part{Probability}
% \section{Interpreting probability using measure theory}
% \subsection{Transfer of terminology}
% From now on the measure space $(X,\A,\mu)$ will be replaced by $(\Omega,\F,P)$ with $P(\Omega)=1$, which we call a \df{probability space}. Given two measurable spaces $(\Omega,\F)$ and $(S,\mathcal{S})$, an $\F/\mathcal{S}$-measurable function $X\colon \Omega \to S$ is called a \df{random variable}. If $(S,\mathcal{S}) = (\R,\B)$, we call the random variable \df[real-valued random variable]{real-valued}.

% Given a probability measure $P$ and a random variable $X$, following \cref{sec:image-measure} we may define a probability measure $\mu$ on $(S,\mathcal{S})$ given by \[
%     \mu(E) = P\bigl(X^{-1}(E)\bigr) = P(X\in E) \text{ for all }E\in \mathcal{S}.
% \] We call this the \df{probability distribution} of $X$. The $X \in E$ above is a shorthand for $\{\omega\in \Omega:X(\omega)\in E\}$, and this convention is widely adopted throughout probability, as long as the context is clear. It also corresponds to the intuitive understanding of a random variable $X$ as a ``variable'' taking random values by ignoring the underlying $\omega$, but we must not take this formally.

% The \df[cumulative distribution function@(cumulative) distribution function]{(cumulative) distribution function} of a real-valued random variable $X$ is defined to be a function $F\colon \R \to [0,1]$ given by \[
%     F(x) = P(X \leq x) = \mu(-\infty,x].
% \]

% We now slightly modify \cref{thm:increasing-rcont-Borel-measure-connection}\ref{enu:CDF-measure}\ref{enu:measure-CDF} to suit our purpose. Note now we instead start with the original part~\ref{enu:measure-CDF}.
% \begin{thm} \label{thm:measure-CDF-prob}
%     Let $X$ be a real-valued random variable with distribution $\mu$, then its distribution function $F$ has the following properties:
%         \begin{itemize}
%             \item $\lim_{x \to -\infty} F(x) = 0$ and $\lim_{x \to \infty} F(x) = 1$;
%             \item it is increasing and right-continuous; 
%             \item it has left limits in the sense that \[
%                 F(x-) = \lim_{y \to x^-} F(y) = \mu(-\infty,x),
%             \] which also implies $\mu(\{x\}) = F(x) - F(x-)$.
%         \end{itemize}
% \end{thm}
% Since $\mu$ is now a probability measure, the first bullet point follows directly. The rest has been proved already before.

% Recall \cref{thm:increasing-rcont-Borel-measure-connection}\ref{enu:CDF-measure}. We can slightly modify its statement and proof to get the version for obtaining a unique Borel probability measure.

% \begin{thm} \label{thm:CDF-measure-prob}
%     Conversely, let $F\colon \R\to [0,1]$ be an increasing, right-continuous function with \[
%         \lim_{x \to -\infty} F(x) = 0\quad \text{and} \quad \lim_{x \to \infty} F(x) = 1,
%     \] then there is a unique probability measure $\mu$ on $(\R,\B)$ such that \[
%         \mu(-\infty,x] = F(x) \quad \text{for all }x\in \R.
%     \]
% \end{thm}

% \Cref{thm:CDF-measure-prob} tells us that as long as we have the distribution function of a random variable $X$, which increases from $0$ to $1$ and is right-continuous, then the distribution function determines the distribution of the random variable. Formally we can state 
% \begin{cor}
%     For two real-valued random variables $X$ and $Y$, we have $F_X = F_Y$ if and only if $\mu_X = \mu_Y$.
% \end{cor}

% This observation further suggests that given a random variable, we may specify its distribution solely in terms of a function $F\colon \R \to [0,1]$ that is increasing, right-continuous, with \[
%         \lim_{x \to -\infty} F(x) = 0\quad \text{and} \quad \lim_{x \to \infty} F(x) = 1.
% \] We call such a function $F$ a \df[cumulative distribution function@(cumulative) distribution function]{(cumulative) distribution function} on its own.

% \begin{thm}
%     Indeed any distribution function $F \colon \R \to [0,1]$ can be realized as the distribution function of some random variable $X$ on some probability space $(\Omega,\F,P)$.
% \end{thm}
% \begin{proof}[First Proof]
%     By \cref{thm:CDF-measure-prob}, we know every distribution function $F$ gives rise to a unique probability measure $\mu$ on $(\R,\B)$. Now let $(\Omega,\F,P) = (\R,\B,\mu)$ and let $X$ be the identity map on $\R$.
% \end{proof}
% As long as one knows \cref{thm:CDF-measure-prob}, this first proof is indeed a very trivial construction. The second proof, independent of \cref{thm:CDF-measure-prob}, might be a bit more interesting to us now.
% \begin{proof}[Second Proof]
%     Let $(\Omega,\F,P) = ([0,1],\B_{[0,1]},m)$, and we define \[
%         X = \sup\{y : F(y) < \omega\} = \inf\{y : F(y) \geq \omega\}
%     \]
% \end{proof}


% The \df[probability density function@(probability) density function]{(probability) density function} of a random variable $X$ is the Radon--Nikodym derivative $d\mu/dm$ of the probability distribution with respect to the Lebesgue measure.

% A polish space is separable and admits a complete metrization.

% \subsection{Independence}

% \subsection{Gaussian measures}
% \begin{namedthm}[Kolmogorov’s extension theorem]
    
% \end{namedthm}

% Bogachev Theorem 1.4.3.

% \section{Random variables and expected values}\label{sec:rv-expec}
% \subsection{Independence}

% \section{Convergence of probability measures}

% \section{Conditional expectations and martingales}
% \begin{defn}
%     Let $\E \abs{X} < \infty$, and $\G$ be a sub-$\sigma$-field of $\F$. Define the \df{conditional expectation} of $X$ given $\G$ to be the random variable $Y$ satisfying \begin{enumerate}
%         \item $Y$ is $\G$-measurable; 
%         \item $\E(Y \ind_{G}) = \E(X \ind_G)$ for all $G \in \G$.
%     \end{enumerate}
%     This $Y$ is denoted by $\E(X \giv \G)$.
% \end{defn}

% We first show that the above definition makes sense from a purely measure-theoretic point of view, and is unique a.s.
% Notice that the function $\nu\colon \mathcal{G} \to \R$ given by \begin{equation} \label{eq:cond-expec-signed-meas}
%     \nu(G) = \E(X\ind_G) = \int_G X \,dP
% \end{equation} is a signed measure, and $\nu \ll P$. Therefore by the \nameref{thm:Radon-Nikodym} for a signed measure and a finite positive measure, there exists a random variable $Y$, unique in $L^1(\Omega,\G,P)$, such that \[
%     \nu(G) = \int_G Y \,dP = \E(Y\ind_G)
% \] for all $G\in \G$.

% % Note that there does not exist a version of conditional expectation $\E(X\giv \G)$ defined specifically for nonnegative $X$. This is because the $\nu$ we defined in \eqref{eq:cond-expec-signed-meas} may become possibly infinite. We have discussed previously that there does not exist a nice Radon--Nikodym theorem for a general infinite measure $\nu$.

% \begin{defn}
%     Define the conditional probability of $A \in \F$ given a sub-$\sigma$-field $\G$ of $\F$ to be $\E(\ind_A \giv \G)$, which we denote by $P(A\giv \G)$.
% \end{defn}

% When $X = \ind_A$, the $\nu(G)$ in \eqref{eq:cond-expec-signed-meas} now becomes $P(A\cap G)$. The conditional probability $P(A \giv \G)$ is therefore the Radon--Nikodym derivative of the probability measure $\nu$ (that takes the information $\G$) with respect to the original probability measure $P$.

% \section{Some ergodic theory}
% \begin{defn}
    
% \end{defn}

% \newpage
% \phantomsection
% \addcontentsline{toc}{part}{Epilogue}
% \part*{\Large Epilogue}

% \newpage
% % \nocite{*}
% \phantomsection
% \addcontentsline{toc}{part}{Bibliography}
% \printbibliography

% \newpage
% \phantomsection
% \addcontentsline{toc}{part}{List of Definitions}
% \printindex
% \end{document}